{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Visualization_deeplift.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khare19yash/Automated-Detection-of-Neuropsychiatric-Disorders/blob/master/Visualization_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbcNNOwas0t2",
        "outputId": "773882dd-9baf-40cf-b2f5-0a9620937f91"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZFE-Yyss5RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd1c2fb7-b990-489d-ae8d-ae1913f906ae"
      },
      "source": [
        "cd /content/gdrive/MyDrive/Thesis/ASD/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Thesis/ASD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "parameters"
        ],
        "execution": {
          "iopub.status.busy": "2021-06-18T20:06:35.313833Z",
          "iopub.execute_input": "2021-06-18T20:06:35.314183Z",
          "iopub.status.idle": "2021-06-18T20:06:35.320917Z",
          "shell.execute_reply.started": "2021-06-18T20:06:35.31415Z",
          "shell.execute_reply": "2021-06-18T20:06:35.320107Z"
        },
        "trusted": true,
        "id": "Y0UrH07ohkn1"
      },
      "source": [
        "#options: cc200, dosenbach160, aal\n",
        "p_ROI = \"cc200\"\n",
        "p_fold = 10\n",
        "p_center = \"Stanford\"\n",
        "p_mode = \"whole\"\n",
        "p_augmentation = False\n",
        "p_Method = \"ASD-DiagNet\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T20:06:35.6938Z",
          "iopub.execute_input": "2021-06-18T20:06:35.694114Z",
          "iopub.status.idle": "2021-06-18T20:06:35.705229Z",
          "shell.execute_reply.started": "2021-06-18T20:06:35.694082Z",
          "shell.execute_reply": "2021-06-18T20:06:35.703223Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XvyvjLghkn2",
        "outputId": "a66bdc5a-8d81-40db-db9b-6585688be9da"
      },
      "source": [
        "parameter_list = [p_ROI,p_fold,p_center,p_mode,p_augmentation,p_Method]\n",
        "print(\"*****List of patameters****\")\n",
        "print(\"ROI atlas: \",p_ROI)\n",
        "print(\"per Center or whole: \",p_mode)\n",
        "if p_mode == 'percenter':\n",
        "    print(\"Center's name: \",p_center)\n",
        "print(\"Method's name: \",p_Method)\n",
        "if p_Method == \"ASD-DiagNet\":\n",
        "    print(\"Augmentation: \",p_augmentation)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****List of patameters****\n",
            "ROI atlas:  cc200\n",
            "per Center or whole:  whole\n",
            "Method's name:  ASD-DiagNet\n",
            "Augmentation:  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSeVPBEwtX_C",
        "outputId": "f02462fb-f471-4499-fdff-8b2c6dd12c71"
      },
      "source": [
        "!pip install pyprind"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyprind\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: pyprind\n",
            "Successfully installed pyprind-2.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T20:06:36.027823Z",
          "iopub.execute_input": "2021-06-18T20:06:36.028151Z",
          "iopub.status.idle": "2021-06-18T20:06:38.856661Z",
          "shell.execute_reply.started": "2021-06-18T20:06:36.028106Z",
          "shell.execute_reply": "2021-06-18T20:06:38.855715Z"
        },
        "trusted": true,
        "id": "5IcOJBWphkn3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from functools import reduce\n",
        "from sklearn.impute import SimpleImputer\n",
        "import time\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import sys\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy import stats\n",
        "from sklearn import tree\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "import functools\n",
        "import numpy.ma as ma # for masked arrays\n",
        "import pyprind\n",
        "import random\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from itertools import groupby\n",
        "import sklearn\n",
        "import pyprind\n",
        "# import wandb\n",
        "# !wandb login d164742a4a99e4e581f543102aff0992153ad225"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz3YnOOchkn3"
      },
      "source": [
        "## Loading the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T20:06:38.861206Z",
          "iopub.execute_input": "2021-06-18T20:06:38.861461Z",
          "iopub.status.idle": "2021-06-18T20:06:38.868954Z",
          "shell.execute_reply.started": "2021-06-18T20:06:38.861434Z",
          "shell.execute_reply": "2021-06-18T20:06:38.868167Z"
        },
        "trusted": true,
        "id": "PmnCD4dphkn4"
      },
      "source": [
        "def get_key(filename):\n",
        "    f_split = filename.split('_')\n",
        "    if f_split[3] == 'rois':\n",
        "        key = '_'.join(f_split[0:3]) \n",
        "    else:\n",
        "        key = '_'.join(f_split[0:2])\n",
        "    return key"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T20:06:38.87189Z",
          "iopub.execute_input": "2021-06-18T20:06:38.872152Z",
          "iopub.status.idle": "2021-06-18T20:06:38.923819Z",
          "shell.execute_reply.started": "2021-06-18T20:06:38.872107Z",
          "shell.execute_reply": "2021-06-18T20:06:38.922494Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBaX2AXuhkn4",
        "outputId": "b7a2d644-7130-49cf-efef-5ec1b55fa9f0"
      },
      "source": [
        "cc200_data_path = './Datasets/CPAC/rois_cc200'          #cc200'#path to time series data\n",
        "data_df = pd.read_csv('./Phenotypes/Phenotypic_V1_0b_preprocessed949.csv',encoding= 'unicode_escape')#path \n",
        "data_df.DX_GROUP = data_df.DX_GROUP.map({1: 1, 2:0})\n",
        "data_df['FILE_PATH'] = data_df['FILE_ID'].apply(lambda x : os.path.join(cc200_data_path,x + '_rois_cc200.1D')) \n",
        "\n",
        "print('Length of data frame : ', len(data_df))\n",
        "print('Sample file path : ', data_df['FILE_PATH'].values[0])\n",
        "print(data_df.head())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of data frame :  949\n",
            "Sample file path :  ./Datasets/CPAC/rois_cc200/Pitt_0050003_rois_cc200.1D\n",
            "   Unnamed: 0  ...                                          FILE_PATH\n",
            "0           0  ...  ./Datasets/CPAC/rois_cc200/Pitt_0050003_rois_c...\n",
            "1           1  ...  ./Datasets/CPAC/rois_cc200/Pitt_0050004_rois_c...\n",
            "2           2  ...  ./Datasets/CPAC/rois_cc200/Pitt_0050006_rois_c...\n",
            "3           3  ...  ./Datasets/CPAC/rois_cc200/Pitt_0050007_rois_c...\n",
            "4           4  ...  ./Datasets/CPAC/rois_cc200/Pitt_0050009_rois_c...\n",
            "\n",
            "[5 rows x 107 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7DgqnL6hkn4"
      },
      "source": [
        "### Helper functions for computing correlations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T20:06:38.925344Z",
          "iopub.execute_input": "2021-06-18T20:06:38.925672Z",
          "iopub.status.idle": "2021-06-18T20:06:38.942734Z",
          "shell.execute_reply.started": "2021-06-18T20:06:38.925638Z",
          "shell.execute_reply": "2021-06-18T20:06:38.941792Z"
        },
        "trusted": true,
        "id": "CrCnO-6yhkn5"
      },
      "source": [
        "def get_label(filename):\n",
        "    assert (filename in labels)\n",
        "    return labels[filename]\n",
        "\n",
        "def get_corr_data(df):\n",
        "              \n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        corr = np.nan_to_num(np.corrcoef(df.T))\n",
        "        mask = np.invert(np.tri(corr.shape[0], k=-1, dtype=bool))\n",
        "        m = ma.masked_where(mask == 1, mask)\n",
        "        return ma.masked_where(m, corr).compressed()\n",
        "        \n",
        "def get_corr_matrix(filename,data_path):\n",
        "    # returns correlation matrix\n",
        "    for file in os.listdir(data_path):\n",
        "        if file.startswith(filename):\n",
        "            df = pd.read_csv(os.path.join(data_path, file), sep='\\t')\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        corr = np.nan_to_num(np.corrcoef(df.T))\n",
        "        return corr\n",
        "\n",
        "def confusion(g_turth,predictions):\n",
        "    tn, fp, fn, tp = confusion_matrix(g_turth,predictions).ravel()\n",
        "    accuracy = (tp+tn)/(tp+fp+tn+fn)\n",
        "    sensitivity = (tp)/(tp+fn)\n",
        "    specificty = (tn)/(tn+fp)\n",
        "    return accuracy,sensitivity,specificty\n",
        "\n",
        "def get_regs(samplesnames,regnum):\n",
        "    # returns region index array\n",
        "    datas = []\n",
        "    for sn in samplesnames:\n",
        "        datas.append(all_corr[sn][0])\n",
        "    datas = np.array(datas)     # datas shape len(samplesnames)x19900\n",
        "    avg=[]\n",
        "    for ie in range(datas.shape[1]):\n",
        "        avg.append(np.mean(datas[:,ie]))\n",
        "    avg=np.array(avg)\n",
        "    highs=avg.argsort()[-regnum:][::-1]\n",
        "    lows=avg.argsort()[:regnum][::-1]\n",
        "    regions=np.concatenate((highs,lows),axis=0) # shape (9950,)\n",
        "    return regions"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbKoDX2y4Qzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba49843-0330-45c0-a841-b9c94a8cf7c5"
      },
      "source": [
        "labels = data_df['DX_GROUP'].values\n",
        "fpaths = data_df['FILE_PATH'].values\n",
        "flist = data_df['FILE_ID'].values\n",
        "\n",
        "print(\"Unique values in labels : \", np.unique(labels, return_counts = True))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in labels :  (array([0, 1]), array([530, 419]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T20:06:38.945281Z",
          "iopub.execute_input": "2021-06-18T20:06:38.94597Z",
          "iopub.status.idle": "2021-06-18T20:07:07.764978Z",
          "shell.execute_reply.started": "2021-06-18T20:06:38.945932Z",
          "shell.execute_reply": "2021-06-18T20:07:07.763126Z"
        },
        "trusted": true,
        "id": "mfjFNCivhkn6"
      },
      "source": [
        "# all_corr = {}\n",
        "\n",
        "# for i,path in enumerate(fpaths):\n",
        "#     key = flist[i]\n",
        "#     x = np.loadtxt(path)\n",
        "#     x = np.array(x, dtype = 'float32')\n",
        "#     x = get_corr_data(x)\n",
        "#     all_corr[key] = (x,labels[i])\n",
        "# print('Length of correlations vector : ', len(all_corr))\n",
        "# pickle.dump(all_corr, open('./data/SFC_CC200.pkl', 'wb'))\n",
        "# # pickle.dump(all_corr, open('./data/Timeseries_CC200.pkl', 'wb'))\n",
        "# print('Length of correlation vector in all_corr : ', len(all_corr[flist[0]][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3zlWZzR1qm6"
      },
      "source": [
        "all_corr = pickle.load(open('./data/SFC_CC200.pkl', 'rb'))\n",
        "# all_corr = pickle.load(open('./data/Timeseries_CC200.pkl', 'rb'))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5Jt7edf_yzm",
        "outputId": "20c81012-d8a1-41c8-d71f-96c3c4256694"
      },
      "source": [
        "print(len(flist))\n",
        "print(flist[ : 10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "949\n",
            "['Pitt_0050003' 'Pitt_0050004' 'Pitt_0050006' 'Pitt_0050007'\n",
            " 'Pitt_0050009' 'Pitt_0050010' 'Pitt_0050011' 'Pitt_0050013'\n",
            " 'Pitt_0050014' 'Pitt_0050015']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch18LNuR-lfI"
      },
      "source": [
        "# sfc = []\n",
        "# labels = []\n",
        "# for i,f in enumerate(flist):\n",
        "#     sfc.append(all_corr[f][0])\n",
        "#     labels.append(all_corr[f][1])\n",
        "\n",
        "# sfc = np.asarray(sfc)\n",
        "# labels = np.asarray(labels)\n",
        "# print('SFC Shape : ',sfc.shape)\n",
        "# print('Labels Shape : ', labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ_26cIy0L2Y",
        "outputId": "cc1e24d9-1181-40d5-e109-a61329ba2cd4"
      },
      "source": [
        "np.unique(labels, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([530, 419]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T7UL0jw0VGO",
        "outputId": "6771427d-fdb9-400b-e677-ec3d341f4bb5"
      },
      "source": [
        "print(len(all_corr))\n",
        "print(all_corr[flist[0]][0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "949\n",
            "(19900,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5daHy9cVnrKp"
      },
      "source": [
        "class ASDDataset(Dataset):\n",
        "    def __init__(self, all_corr, samples):\n",
        "        self.corr = all_corr\n",
        "        self.samples = samples\n",
        "        pass\n",
        "    def __getitem__(self,idx):\n",
        "        return torch.tensor(self.corr[self.samples[idx]][0],dtype=torch.float),torch.tensor(self.corr[self.samples[idx]][1],dtype=torch.float)\n",
        "        pass\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWyj8pQihkn7"
      },
      "source": [
        "# Defining Autoencoder class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T20:29:50.96222Z",
          "iopub.execute_input": "2021-06-18T20:29:50.962557Z",
          "iopub.status.idle": "2021-06-18T20:29:51.064936Z",
          "shell.execute_reply.started": "2021-06-18T20:29:50.962527Z",
          "shell.execute_reply": "2021-06-18T20:29:51.06403Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i14YCA9Lhkn8",
        "outputId": "71fe7c9e-2e0a-46c1-bf8b-b4c009dfeaba"
      },
      "source": [
        "class MTAutoEncoder(nn.Module):\n",
        "    def __init__(self, num_inputs=990, \n",
        "                 num_latent=200, tied=True,\n",
        "                 num_classes=2, use_dropout=False):\n",
        "        super(MTAutoEncoder, self).__init__()\n",
        "        \n",
        "        self.num_latent = num_latent\n",
        "        self.num_inputs = num_inputs\n",
        "        \n",
        "        self.fc_encoder = nn.Sequential (\n",
        "                nn.Linear(self.num_inputs,4096),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(4096,1024),\n",
        "                nn.Tanh())\n",
        "        \n",
        "        self.fc_decoder = nn.Sequential (\n",
        "                nn.Linear(1024,4096),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(4096,self.num_inputs),\n",
        "                nn.Tanh())\n",
        "         \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        if use_dropout:\n",
        "            self.classifier = nn.Sequential (\n",
        "                nn.Dropout(p=0.25),\n",
        "                nn.Linear(1024, 1),\n",
        "#                 nn.Sigmoid(),\n",
        "#                 nn.Linear(128, 1),\n",
        "\n",
        "            )\n",
        "        else:\n",
        "            self.classifier = nn.Sequential (\n",
        "                nn.Linear(1024, 1),\n",
        "#                 nn.Sigmoid(),\n",
        "#                 nn.Linear(128, 1),\n",
        "            )\n",
        "            \n",
        "         \n",
        "    def forward(self, x, eval_classifier=True):\n",
        "\n",
        "        x = self.fc_encoder(x)\n",
        "        if eval_classifier:\n",
        "            x_logit = self.classifier(x)   #   .squeeze(1)\n",
        "            x_logit = self.sigmoid(x_logit)\n",
        "            return x_logit \n",
        "\n",
        "        x = self.fc_decoder(x)        \n",
        "        return x\n",
        "\n",
        "model = MTAutoEncoder()\n",
        "\n",
        "model"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MTAutoEncoder(\n",
              "  (fc_encoder): Sequential(\n",
              "    (0): Linear(in_features=990, out_features=4096, bias=True)\n",
              "    (1): Tanh()\n",
              "    (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (3): Tanh()\n",
              "  )\n",
              "  (fc_decoder): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "    (1): Tanh()\n",
              "    (2): Linear(in_features=4096, out_features=990, bias=True)\n",
              "    (3): Tanh()\n",
              "  )\n",
              "  (sigmoid): Sigmoid()\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw6wxQ7uhkn8"
      },
      "source": [
        "# Defining training and testing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T20:29:54.242475Z",
          "iopub.execute_input": "2021-06-18T20:29:54.242797Z",
          "iopub.status.idle": "2021-06-18T20:29:54.272092Z",
          "shell.execute_reply.started": "2021-06-18T20:29:54.242766Z",
          "shell.execute_reply": "2021-06-18T20:29:54.271229Z"
        },
        "trusted": true,
        "id": "XJGFx-CFhkn8"
      },
      "source": [
        "def train(model, epoch, train_loader, p_bernoulli=None, mode='both', lam_factor=1.0):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    clf_train_loss = []\n",
        "    ae_train_loss = []\n",
        "    \n",
        "    if mode == 'clf':\n",
        "        final_targets = []\n",
        "        final_predictions = []\n",
        "    else:\n",
        "        final_targets = None\n",
        "        final_predictions = None    \n",
        "    \n",
        "    for i,(batch_x,batch_y) in enumerate(train_loader):\n",
        "        if len(batch_x) != batch_size:\n",
        "            continue\n",
        "        if p_bernoulli is not None:\n",
        "            if i == 0:\n",
        "                p_tensor = torch.ones_like(batch_x).to(device)*p_bernoulli\n",
        "            rand_bernoulli = torch.bernoulli(p_tensor).to(device)\n",
        "\n",
        "        data, target = batch_x.to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if mode == 'ae':\n",
        "            if p_bernoulli is not None:\n",
        "                rec_noisy = model(data*rand_bernoulli, False)\n",
        "                loss_ae = criterion_ae(rec_noisy, data) / len(batch_x)\n",
        "            else:\n",
        "                rec = model(data, False)\n",
        "                loss_ae = criterion_ae(rec, data) / len(batch_x)\n",
        "                \n",
        "            loss_total = loss_ae\n",
        "            loss_ae_np = loss_ae.detach().cpu().numpy()\n",
        "            \n",
        "            clf_train_loss.append(0.0)\n",
        "            ae_train_loss.append(loss_ae_np)\n",
        "            train_losses.append([loss_ae_np, 0.0])\n",
        "                \n",
        "        if mode == 'clf':\n",
        "            logits = model(data, True)\n",
        "            logits = np.squeeze(logits, 1)\n",
        "            loss_clf = criterion_clf(logits, target)\n",
        "\n",
        "            proba = logits.detach().cpu().numpy()\n",
        "            # proba = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "            predictions = np.ones_like(proba, dtype=np.int32)\n",
        "            predictions[proba < 0.5] = 0\n",
        "            \n",
        "            final_targets.append(target.detach().cpu().numpy())\n",
        "            final_predictions.append(predictions)\n",
        "            \n",
        "            loss_total = loss_clf\n",
        "            loss_clf_np = loss_clf.detach().cpu().numpy()\n",
        "            \n",
        "            clf_train_loss.append(loss_clf_np)\n",
        "            ae_train_loss.append(0.0)\n",
        "            train_losses.append([0.0,loss_clf_np])\n",
        "            \n",
        "\n",
        "        loss_total.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    if (final_targets is not None) and (final_predictions is not None):\n",
        "        final_targets = np.concatenate(final_targets)\n",
        "        final_predictions = np.concatenate(final_predictions)\n",
        "        train_accuracy = np.mean(final_targets == final_predictions)\n",
        "\n",
        "        return np.mean(clf_train_loss), train_accuracy\n",
        "    else:\n",
        "        return np.mean(ae_train_loss), None\n",
        "\n",
        "def validate(model, epoch, train_loader, mode='ae', lam_factor=1.0):\n",
        "    model.eval()\n",
        "    train_losses = []\n",
        "    clf_train_loss = []\n",
        "    ae_train_loss = []\n",
        "    \n",
        "    if mode == 'clf':\n",
        "        final_targets = []\n",
        "        final_predictions = []\n",
        "    else:\n",
        "        final_targets = None\n",
        "        final_predictions = None    \n",
        "    \n",
        "    for i,(batch_x,batch_y) in enumerate(train_loader):\n",
        "        if len(batch_x) != batch_size:\n",
        "            continue\n",
        "        data, target = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "        if mode == 'ae':\n",
        "            rec = model(data, False)\n",
        "            loss_ae = criterion_ae(rec, data) / len(batch_x)\n",
        "                \n",
        "            loss_total = loss_ae\n",
        "            loss_ae_np = loss_ae.detach().cpu().numpy()\n",
        "            \n",
        "            clf_train_loss.append(0.0)\n",
        "            ae_train_loss.append(loss_ae_np)\n",
        "            train_losses.append([loss_ae_np, 0.0])\n",
        "                \n",
        "        if mode == 'clf':\n",
        "            logits = model(data, True)\n",
        "            logits = np.squeeze(logits, 1)\n",
        "            loss_clf = criterion_clf(logits, target)\n",
        "            \n",
        "            proba = logits.detach().cpu().numpy()\n",
        "            # proba = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "            predictions = np.ones_like(proba, dtype=np.int32)\n",
        "            predictions[proba < 0.5] = 0\n",
        "            \n",
        "            final_targets.append(target.detach().cpu().numpy())\n",
        "            final_predictions.append(predictions)\n",
        "            \n",
        "            loss_total = loss_clf\n",
        "            loss_clf_np = loss_clf.detach().cpu().numpy()\n",
        "            \n",
        "            clf_train_loss.append(loss_clf_np)\n",
        "            ae_train_loss.append(0.0)\n",
        "            train_losses.append([0.0,loss_clf_np])\n",
        "    \n",
        "    if (final_targets is not None) and (final_predictions is not None):\n",
        "        final_targets = np.concatenate(final_targets)\n",
        "        final_predictions = np.concatenate(final_predictions)\n",
        "        train_accuracy = np.mean(final_targets == final_predictions)\n",
        "\n",
        "        return np.mean(clf_train_loss), train_accuracy\n",
        "    else:\n",
        "        return np.mean(ae_train_loss), None\n",
        "\n",
        "\n",
        "def test(model, criterion, test_loader, \n",
        "         eval_classifier=False, num_batch=None):\n",
        "    test_loss, n_test, correct = 0.0, 0, 0\n",
        "    eval_loss = []\n",
        "    all_predss=[]\n",
        "    if eval_classifier:\n",
        "        y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for i,(batch_x,batch_y) in enumerate(test_loader):\n",
        "            if num_batch is not None:\n",
        "                if i >= num_batch:\n",
        "                    continue\n",
        "            data, target = batch_x.to(device), batch_y.to(device)\n",
        "            logits = model(data, eval_classifier)\n",
        "            logits = np.squeeze(logits, 1)\n",
        "#             test_loss += criterion(rec, data).detach().cpu().numpy() \n",
        "#             n_test += len(batch_x)\n",
        "            # target = np.squeeze(target, 1)\n",
        "            test_loss = criterion(logits, target).detach().cpu().numpy() \n",
        "            eval_loss.append(test_loss)\n",
        "            if eval_classifier:\n",
        "                proba = logits.detach().cpu().numpy()\n",
        "                # proba = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "                preds = np.ones_like(proba, dtype=np.int32)\n",
        "                preds[proba < 0.5] = 0\n",
        "                all_predss.extend(preds)###????\n",
        "                y_arr = np.array(batch_y, dtype=np.int32)\n",
        "\n",
        "                correct += np.sum(preds == y_arr)\n",
        "                y_true.extend(y_arr.tolist())\n",
        "                y_pred.extend(proba.tolist())\n",
        "        mlp_acc,mlp_sens,mlp_spef = confusion(y_true,all_predss)\n",
        "        metrics_dict = {'accuracy': np.round(mlp_acc, 4), \n",
        "                        'senstivity' : np.round(mlp_sens,4), \n",
        "                        'specificity' : np.round(mlp_spef,4), \n",
        "                        'loss' : np.round(np.mean(eval_loss),4)}\n",
        "        \n",
        "    return  metrics_dict"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-18T20:29:55.7098Z",
          "iopub.execute_input": "2021-06-18T20:29:55.710152Z",
          "iopub.status.idle": "2021-06-18T20:29:55.718895Z",
          "shell.execute_reply.started": "2021-06-18T20:29:55.710095Z",
          "shell.execute_reply": "2021-06-18T20:29:55.718161Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTlD8687hkn9",
        "outputId": "8a6e5ec7-94d2-4658-ed0a-fc186c37fc0b"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEYrLdqSCM7D"
      },
      "source": [
        "def attribute_image_features(algorithm, inputs):\n",
        "    model.zero_grad()\n",
        "    model.eval()\n",
        "    tensor_attributions = algorithm.attribute(inputs = inputs, target = 0, return_convergence_delta=True)  \n",
        "    return tensor_attributions"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDhqS1mBHfWc",
        "outputId": "01ce9596-7587-4e62-86be-81e6bcd65b26"
      },
      "source": [
        "!pip install captum"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting captum\n",
            "  Downloading captum-0.4.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 122 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 133 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 143 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 153 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 163 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 174 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 184 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 194 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 204 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 215 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 225 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 235 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 245 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 256 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 266 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 276 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 286 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 296 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 307 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 317 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 327 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 337 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 348 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 358 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 368 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 378 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 389 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 399 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 409 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 419 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 430 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 440 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 450 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 460 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 471 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 481 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 491 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 501 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 512 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 522 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 532 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 542 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 552 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 563 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 573 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 583 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 593 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 604 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 614 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 624 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 634 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 645 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 655 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 665 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 675 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 686 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 696 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 706 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 716 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 727 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 737 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 747 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 757 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 768 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 778 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 788 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 798 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 808 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 819 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 829 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 839 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 849 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 860 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 870 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 880 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 890 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 901 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 911 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 921 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 931 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 942 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 952 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 962 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 972 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 983 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 993 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.0 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.0 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.1 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.2 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.2 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.2 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.2 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.2 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.3 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.3 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.3 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.3 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.4 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4 MB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4 MB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from captum) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->captum) (3.10.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->captum) (1.15.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxl4AEHHHWm0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from captum.attr import IntegratedGradients\n",
        "from captum.attr import Saliency\n",
        "from captum.attr import DeepLift\n",
        "from captum.attr import NoiseTunnel\n",
        "from captum.attr import visualization as viz\n",
        "from captum.attr import Saliency\n",
        "import torchvision"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEsTbR4mxh5A"
      },
      "source": [
        "# ASD 2 Layer Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9532M-9sEBY",
        "outputId": "31742630-5e65-4533-da42-e39f659143e3"
      },
      "source": [
        "if p_Method == \"ASD-DiagNet\" and p_mode == \"whole\":\n",
        "    \n",
        "    start = time.time()\n",
        "    batch_size = 16\n",
        "    learning_rate_ae, learning_rate_clf = 0.0001, 0.0001\n",
        "    ae_epochs = 50      # 50\n",
        "    clf_epochs = 50      # 50\n",
        "\n",
        "    p_bernoulli = None\n",
        "    augmentation = p_augmentation\n",
        "    use_dropout = True\n",
        "\n",
        "    start= time.time()\n",
        "\n",
        "    repeat_acc = []\n",
        "    repeat_sen = []\n",
        "    repeat_spec = []\n",
        "    repeat_loss = []    \n",
        "    df = {}\n",
        "    for rp in range(1):\n",
        "\n",
        "        kf = StratifiedKFold(n_splits=p_fold, random_state=1, shuffle=True)\n",
        "\n",
        "        crossval_acc, crossval_sen, crossval_spec, crossval_loss, attributions = [], [], [], [], []\n",
        "\n",
        "        for kk,(train_index, test_index) in enumerate(kf.split(flist, labels)):\n",
        "\n",
        "            \n",
        "            train_samples, test_samples = flist[train_index],flist[test_index]\n",
        "            train_labels = labels[train_index]\n",
        "            \n",
        "            train_samples, val_samples, train_labels, val_labels = train_test_split(train_samples, train_labels, test_size = 0.25,\n",
        "                                                              random_state = 42, stratify = train_labels)\n",
        "            \n",
        "            print('Number of train samples : ', len(train_samples))\n",
        "            print('Number of val samples : ', len(val_samples))\n",
        "            print('Number of test samples : ', len(test_samples))\n",
        "\n",
        "            samples_dict = {} \n",
        "            samples_dict['train'] = train_samples\n",
        "            samples_dict['val'] = val_samples\n",
        "            samples_dict['test'] = test_samples\n",
        "\n",
        "            df[kk] = samples_dict\n",
        "            verbose = (True if (kk == 0) else False)\n",
        "\n",
        "            num_inpp = 19900\n",
        "            n_lat = 512\n",
        "            \n",
        "            train_dataset = ASDDataset(all_corr, train_samples)\n",
        "            val_dataset = ASDDataset(all_corr, val_samples)\n",
        "            test_dataset = ASDDataset(all_corr, test_samples)\n",
        "            \n",
        "            train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "            val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
        "            test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)                           \n",
        "\n",
        "            model = MTAutoEncoder(tied = False, num_inputs = num_inpp, num_latent = n_lat, use_dropout = use_dropout)\n",
        "            model = model.to(device)\n",
        "\n",
        "            criterion_ae = nn.MSELoss(reduction='sum')\n",
        "            criterion_clf = nn.BCELoss()               \n",
        "            optimizer = optim.Adam(model.parameters(),lr = 0.0001, weight_decay = 0.05)          \n",
        "\n",
        "            best_ae_model = None\n",
        "            best_ae_loss = sys.float_info.max\n",
        "            count = 0\n",
        "            \n",
        "            print(\"AE Training Started-----------\")\n",
        "            \n",
        "            for epoch in range(1, ae_epochs+1):\n",
        "\n",
        "                print(f'Epoch {epoch}/{ae_epochs}')\n",
        "\n",
        "                ae_train_loss, _ = train(model, epoch, train_dataloader, p_bernoulli, mode='ae')\n",
        "                print(f'AE Train loss: {(ae_train_loss):.4f}')\n",
        "\n",
        "                ae_val_loss, _ = validate(model, epoch, val_dataloader, mode='ae')\n",
        "                print(f'AE Val loss: {(ae_val_loss):.4f}')\n",
        "\n",
        "                if(ae_val_loss < best_ae_loss):\n",
        "                    best_ae_model = model\n",
        "                    best_ae_loss = ae_val_loss\n",
        "                    count = 1\n",
        "                else:\n",
        "                    count += 1\n",
        "                \n",
        "                if(count == 5):  # Early stopping\n",
        "                    break\n",
        "                    \n",
        "            \n",
        "            print(\"CLF Training Started-----------\")\n",
        "            best_clf_model = None\n",
        "            best_clf_acc = 0.0\n",
        "            count = 0\n",
        "            model = best_ae_model\n",
        "            for epoch in range(1, clf_epochs+1):\n",
        "\n",
        "                print(f'Epoch {epoch}/{clf_epochs}')\n",
        "\n",
        "                clf_train_loss, train_acc = train(model, epoch, train_dataloader, p_bernoulli, mode='clf')\n",
        "                print(f'CLF Train loss: {(clf_train_loss):.4f}, Train Accuracy: {(train_acc):.4f}')\n",
        "\n",
        "                clf_val_loss, val_acc = validate(model, epoch, val_dataloader, mode='clf')\n",
        "                print(f'CLF Val loss: {(clf_val_loss):.4f}, Validation Accuracy: {(val_acc):.4f}')\n",
        "\n",
        "                if(val_acc > best_clf_acc):\n",
        "                    best_clf_model = model\n",
        "                    best_clf_acc = val_acc\n",
        "                    count = 1\n",
        "                else:\n",
        "                    count += 1\n",
        "                \n",
        "                if(count == 10):\n",
        "                    break        \n",
        "\n",
        "            metrics_dict = test(best_clf_model, criterion_clf, test_dataloader, eval_classifier = True)\n",
        "            print(\"-----------------------------\")\n",
        "            print(f'Fold {kk+1}/{p_fold}')\n",
        "            print(f'{metrics_dict}')\n",
        "            print(\"-----------------------------\")\n",
        "            \n",
        "            torch.save(best_clf_model.state_dict(), f'./data/Weights/Fold_{kk+1}.pth')\n",
        "            print(f'Fold {kk+1} weights are saved')\n",
        "\n",
        "            crossval_acc.append(metrics_dict['accuracy'])\n",
        "            crossval_sen.append(metrics_dict['senstivity'])\n",
        "            crossval_spec.append(metrics_dict['specificity'])\n",
        "            crossval_loss.append(metrics_dict['loss'])\n",
        "            \n",
        "            \n",
        "        print(\"*********************************\")   \n",
        "\n",
        "        print(f'Average Value after 10 Folds and repeats one {rp+1}------->')\n",
        "        print(f'Accuracy: {np.round(np.mean(crossval_acc),4)}, Senstivity: {np.round(np.mean(crossval_sen),4)}, Specificity: {np.round(np.mean(crossval_spec),4)}, Loss: {np.round(np.mean(crossval_loss),4)}')\n",
        "        print(\"*********************************\") \n",
        "        \n",
        "        pickle.dump(df, open('./data/AllFoldsSamples.pkl', 'wb'))\n",
        "\n",
        "        repeat_acc.append(np.mean(crossval_acc))\n",
        "        repeat_sen.append(np.mean(crossval_sen))\n",
        "        repeat_spec.append(np.mean(crossval_spec))\n",
        "        repeat_loss.append(np.mean(crossval_loss))\n",
        "    \n",
        "    print(f\"Average Value after 1 Repeat:\")\n",
        "    content = f'Accuracy: {np.round(np.mean(repeat_acc),4)}, Senstivity: {np.round(np.mean(repeat_sen),4)}, Specificity: {np.round(np.mean(repeat_spec),4)}, Loss: {np.round(np.mean(repeat_loss),4)}'\n",
        "    print(content)\n",
        "        \n",
        "    finish= time.time()\n",
        "    print(finish-start)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train samples :  640\n",
            "Number of val samples :  214\n",
            "Number of test samples :  95\n",
            "AE Training Started-----------\n",
            "Epoch 1/50\n",
            "AE Train loss: 778.1338\n",
            "AE Val loss: 706.7473\n",
            "Epoch 2/50\n",
            "AE Train loss: 635.0114\n",
            "AE Val loss: 645.7183\n",
            "Epoch 3/50\n",
            "AE Train loss: 560.5023\n",
            "AE Val loss: 611.9498\n",
            "Epoch 4/50\n",
            "AE Train loss: 504.1945\n",
            "AE Val loss: 589.1733\n",
            "Epoch 5/50\n",
            "AE Train loss: 455.6326\n",
            "AE Val loss: 574.7681\n",
            "Epoch 6/50\n",
            "AE Train loss: 415.0204\n",
            "AE Val loss: 570.8008\n",
            "Epoch 7/50\n",
            "AE Train loss: 379.4040\n",
            "AE Val loss: 552.1918\n",
            "Epoch 8/50\n",
            "AE Train loss: 347.9178\n",
            "AE Val loss: 547.7776\n",
            "Epoch 9/50\n",
            "AE Train loss: 315.0369\n",
            "AE Val loss: 539.2004\n",
            "Epoch 10/50\n",
            "AE Train loss: 287.3580\n",
            "AE Val loss: 530.4305\n",
            "Epoch 11/50\n",
            "AE Train loss: 263.8958\n",
            "AE Val loss: 529.2970\n",
            "Epoch 12/50\n",
            "AE Train loss: 243.5821\n",
            "AE Val loss: 518.0255\n",
            "Epoch 13/50\n",
            "AE Train loss: 225.9075\n",
            "AE Val loss: 514.9936\n",
            "Epoch 14/50\n",
            "AE Train loss: 208.6955\n",
            "AE Val loss: 514.5632\n",
            "Epoch 15/50\n",
            "AE Train loss: 194.2940\n",
            "AE Val loss: 516.5494\n",
            "Epoch 16/50\n",
            "AE Train loss: 182.3839\n",
            "AE Val loss: 511.1699\n",
            "Epoch 17/50\n",
            "AE Train loss: 168.2214\n",
            "AE Val loss: 503.7202\n",
            "Epoch 18/50\n",
            "AE Train loss: 156.4634\n",
            "AE Val loss: 502.0055\n",
            "Epoch 19/50\n",
            "AE Train loss: 148.6368\n",
            "AE Val loss: 500.9510\n",
            "Epoch 20/50\n",
            "AE Train loss: 137.7825\n",
            "AE Val loss: 497.3324\n",
            "Epoch 21/50\n",
            "AE Train loss: 128.8667\n",
            "AE Val loss: 498.6985\n",
            "Epoch 22/50\n",
            "AE Train loss: 120.5093\n",
            "AE Val loss: 497.7780\n",
            "Epoch 23/50\n",
            "AE Train loss: 113.6573\n",
            "AE Val loss: 499.4246\n",
            "Epoch 24/50\n",
            "AE Train loss: 107.6415\n",
            "AE Val loss: 495.2300\n",
            "Epoch 25/50\n",
            "AE Train loss: 100.4532\n",
            "AE Val loss: 490.4834\n",
            "Epoch 26/50\n",
            "AE Train loss: 93.4364\n",
            "AE Val loss: 491.4612\n",
            "Epoch 27/50\n",
            "AE Train loss: 87.9737\n",
            "AE Val loss: 488.0267\n",
            "Epoch 28/50\n",
            "AE Train loss: 83.7437\n",
            "AE Val loss: 489.0999\n",
            "Epoch 29/50\n",
            "AE Train loss: 79.6800\n",
            "AE Val loss: 487.9626\n",
            "Epoch 30/50\n",
            "AE Train loss: 74.5735\n",
            "AE Val loss: 489.2097\n",
            "Epoch 31/50\n",
            "AE Train loss: 70.7601\n",
            "AE Val loss: 484.7061\n",
            "Epoch 32/50\n",
            "AE Train loss: 66.7105\n",
            "AE Val loss: 487.5192\n",
            "Epoch 33/50\n",
            "AE Train loss: 62.7317\n",
            "AE Val loss: 484.7903\n",
            "Epoch 34/50\n",
            "AE Train loss: 60.5697\n",
            "AE Val loss: 486.8951\n",
            "Epoch 35/50\n",
            "AE Train loss: 58.6654\n",
            "AE Val loss: 483.5364\n",
            "Epoch 36/50\n",
            "AE Train loss: 56.2696\n",
            "AE Val loss: 483.4653\n",
            "Epoch 37/50\n",
            "AE Train loss: 54.7534\n",
            "AE Val loss: 484.9278\n",
            "Epoch 38/50\n",
            "AE Train loss: 53.1180\n",
            "AE Val loss: 483.1794\n",
            "Epoch 39/50\n",
            "AE Train loss: 51.3593\n",
            "AE Val loss: 484.4068\n",
            "Epoch 40/50\n",
            "AE Train loss: 49.1343\n",
            "AE Val loss: 483.3687\n",
            "Epoch 41/50\n",
            "AE Train loss: 46.9748\n",
            "AE Val loss: 482.3620\n",
            "Epoch 42/50\n",
            "AE Train loss: 45.4430\n",
            "AE Val loss: 482.5281\n",
            "Epoch 43/50\n",
            "AE Train loss: 43.3809\n",
            "AE Val loss: 485.6477\n",
            "Epoch 44/50\n",
            "AE Train loss: 41.7640\n",
            "AE Val loss: 482.1198\n",
            "Epoch 45/50\n",
            "AE Train loss: 40.0062\n",
            "AE Val loss: 482.1556\n",
            "Epoch 46/50\n",
            "AE Train loss: 38.2362\n",
            "AE Val loss: 480.7719\n",
            "Epoch 47/50\n",
            "AE Train loss: 37.4210\n",
            "AE Val loss: 481.8548\n",
            "Epoch 48/50\n",
            "AE Train loss: 36.9909\n",
            "AE Val loss: 481.7673\n",
            "Epoch 49/50\n",
            "AE Train loss: 36.9628\n",
            "AE Val loss: 484.6906\n",
            "Epoch 50/50\n",
            "AE Train loss: 37.1841\n",
            "AE Val loss: 480.9387\n",
            "CLF Training Started-----------\n",
            "Epoch 1/50\n",
            "CLF Train loss: 0.6999, Train Accuracy: 0.5312\n",
            "CLF Val loss: 0.6576, Validation Accuracy: 0.5865\n",
            "Epoch 2/50\n",
            "CLF Train loss: 0.6525, Train Accuracy: 0.6172\n",
            "CLF Val loss: 0.6345, Validation Accuracy: 0.6154\n",
            "Epoch 3/50\n",
            "CLF Train loss: 0.6219, Train Accuracy: 0.6734\n",
            "CLF Val loss: 0.6171, Validation Accuracy: 0.6298\n",
            "Epoch 4/50\n",
            "CLF Train loss: 0.5978, Train Accuracy: 0.6891\n",
            "CLF Val loss: 0.6042, Validation Accuracy: 0.6635\n",
            "Epoch 5/50\n",
            "CLF Train loss: 0.5749, Train Accuracy: 0.7281\n",
            "CLF Val loss: 0.5935, Validation Accuracy: 0.6731\n",
            "Epoch 6/50\n",
            "CLF Train loss: 0.5510, Train Accuracy: 0.7500\n",
            "CLF Val loss: 0.5847, Validation Accuracy: 0.6875\n",
            "Epoch 7/50\n",
            "CLF Train loss: 0.5266, Train Accuracy: 0.7859\n",
            "CLF Val loss: 0.5765, Validation Accuracy: 0.7067\n",
            "Epoch 8/50\n",
            "CLF Train loss: 0.5115, Train Accuracy: 0.8172\n",
            "CLF Val loss: 0.5686, Validation Accuracy: 0.7212\n",
            "Epoch 9/50\n",
            "CLF Train loss: 0.4838, Train Accuracy: 0.8156\n",
            "CLF Val loss: 0.5632, Validation Accuracy: 0.6875\n",
            "Epoch 10/50\n",
            "CLF Train loss: 0.4672, Train Accuracy: 0.8250\n",
            "CLF Val loss: 0.5563, Validation Accuracy: 0.7308\n",
            "Epoch 11/50\n",
            "CLF Train loss: 0.4467, Train Accuracy: 0.8547\n",
            "CLF Val loss: 0.5526, Validation Accuracy: 0.7115\n",
            "Epoch 12/50\n",
            "CLF Train loss: 0.4237, Train Accuracy: 0.8547\n",
            "CLF Val loss: 0.5475, Validation Accuracy: 0.7019\n",
            "Epoch 13/50\n",
            "CLF Train loss: 0.4092, Train Accuracy: 0.8656\n",
            "CLF Val loss: 0.5432, Validation Accuracy: 0.7019\n",
            "Epoch 14/50\n",
            "CLF Train loss: 0.3800, Train Accuracy: 0.8859\n",
            "CLF Val loss: 0.5396, Validation Accuracy: 0.7260\n",
            "Epoch 15/50\n",
            "CLF Train loss: 0.3654, Train Accuracy: 0.9047\n",
            "CLF Val loss: 0.5398, Validation Accuracy: 0.7163\n",
            "Epoch 16/50\n",
            "CLF Train loss: 0.3411, Train Accuracy: 0.9047\n",
            "CLF Val loss: 0.5333, Validation Accuracy: 0.7260\n",
            "Epoch 17/50\n",
            "CLF Train loss: 0.3166, Train Accuracy: 0.9328\n",
            "CLF Val loss: 0.5344, Validation Accuracy: 0.7212\n",
            "Epoch 18/50\n",
            "CLF Train loss: 0.2996, Train Accuracy: 0.9344\n",
            "CLF Val loss: 0.5330, Validation Accuracy: 0.7212\n",
            "Epoch 19/50\n",
            "CLF Train loss: 0.2844, Train Accuracy: 0.9328\n",
            "CLF Val loss: 0.5319, Validation Accuracy: 0.7308\n",
            "-----------------------------\n",
            "Fold 1/10\n",
            "{'accuracy': 0.7053, 'senstivity': 0.6429, 'specificity': 0.7547, 'loss': 0.5206}\n",
            "-----------------------------\n",
            "Fold 1 weights are saved\n",
            "Number of train samples :  640\n",
            "Number of val samples :  214\n",
            "Number of test samples :  95\n",
            "AE Training Started-----------\n",
            "Epoch 1/50\n",
            "AE Train loss: 777.5909\n",
            "AE Val loss: 712.5990\n",
            "Epoch 2/50\n",
            "AE Train loss: 632.3546\n",
            "AE Val loss: 647.1412\n",
            "Epoch 3/50\n",
            "AE Train loss: 558.7582\n",
            "AE Val loss: 613.9762\n",
            "Epoch 4/50\n",
            "AE Train loss: 501.0809\n",
            "AE Val loss: 592.7761\n",
            "Epoch 5/50\n",
            "AE Train loss: 454.5889\n",
            "AE Val loss: 574.5681\n",
            "Epoch 6/50\n",
            "AE Train loss: 413.3444\n",
            "AE Val loss: 563.3540\n",
            "Epoch 7/50\n",
            "AE Train loss: 376.9675\n",
            "AE Val loss: 551.4622\n",
            "Epoch 8/50\n",
            "AE Train loss: 342.1447\n",
            "AE Val loss: 541.2631\n",
            "Epoch 9/50\n",
            "AE Train loss: 312.2907\n",
            "AE Val loss: 535.8143\n",
            "Epoch 10/50\n",
            "AE Train loss: 290.0841\n",
            "AE Val loss: 536.1746\n",
            "Epoch 11/50\n",
            "AE Train loss: 267.0661\n",
            "AE Val loss: 526.6781\n",
            "Epoch 12/50\n",
            "AE Train loss: 243.6461\n",
            "AE Val loss: 521.3427\n",
            "Epoch 13/50\n",
            "AE Train loss: 224.4062\n",
            "AE Val loss: 513.8899\n",
            "Epoch 14/50\n",
            "AE Train loss: 205.4608\n",
            "AE Val loss: 511.3242\n",
            "Epoch 15/50\n",
            "AE Train loss: 190.8559\n",
            "AE Val loss: 509.1035\n",
            "Epoch 16/50\n",
            "AE Train loss: 179.9652\n",
            "AE Val loss: 507.4478\n",
            "Epoch 17/50\n",
            "AE Train loss: 166.2185\n",
            "AE Val loss: 503.3182\n",
            "Epoch 18/50\n",
            "AE Train loss: 153.2041\n",
            "AE Val loss: 502.8871\n",
            "Epoch 19/50\n",
            "AE Train loss: 142.0573\n",
            "AE Val loss: 499.7521\n",
            "Epoch 20/50\n",
            "AE Train loss: 132.9967\n",
            "AE Val loss: 497.0212\n",
            "Epoch 21/50\n",
            "AE Train loss: 126.4450\n",
            "AE Val loss: 497.3590\n",
            "Epoch 22/50\n",
            "AE Train loss: 119.8643\n",
            "AE Val loss: 497.8659\n",
            "Epoch 23/50\n",
            "AE Train loss: 113.6420\n",
            "AE Val loss: 495.5424\n",
            "Epoch 24/50\n",
            "AE Train loss: 106.3585\n",
            "AE Val loss: 493.7476\n",
            "Epoch 25/50\n",
            "AE Train loss: 100.0566\n",
            "AE Val loss: 491.3685\n",
            "Epoch 26/50\n",
            "AE Train loss: 93.3798\n",
            "AE Val loss: 495.5042\n",
            "Epoch 27/50\n",
            "AE Train loss: 88.5948\n",
            "AE Val loss: 487.1394\n",
            "Epoch 28/50\n",
            "AE Train loss: 83.0539\n",
            "AE Val loss: 489.2054\n",
            "Epoch 29/50\n",
            "AE Train loss: 78.4636\n",
            "AE Val loss: 487.4050\n",
            "Epoch 30/50\n",
            "AE Train loss: 74.3916\n",
            "AE Val loss: 486.2690\n",
            "Epoch 31/50\n",
            "AE Train loss: 70.0631\n",
            "AE Val loss: 486.5456\n",
            "Epoch 32/50\n",
            "AE Train loss: 67.1681\n",
            "AE Val loss: 491.5047\n",
            "Epoch 33/50\n",
            "AE Train loss: 63.8711\n",
            "AE Val loss: 484.7350\n",
            "Epoch 34/50\n",
            "AE Train loss: 60.8184\n",
            "AE Val loss: 483.3600\n",
            "Epoch 35/50\n",
            "AE Train loss: 57.3242\n",
            "AE Val loss: 483.4575\n",
            "Epoch 36/50\n",
            "AE Train loss: 54.3821\n",
            "AE Val loss: 484.6242\n",
            "Epoch 37/50\n",
            "AE Train loss: 52.1969\n",
            "AE Val loss: 481.6063\n",
            "Epoch 38/50\n",
            "AE Train loss: 50.0193\n",
            "AE Val loss: 483.7287\n",
            "Epoch 39/50\n",
            "AE Train loss: 47.7178\n",
            "AE Val loss: 482.4395\n",
            "Epoch 40/50\n",
            "AE Train loss: 45.2038\n",
            "AE Val loss: 482.2180\n",
            "Epoch 41/50\n",
            "AE Train loss: 43.8984\n",
            "AE Val loss: 480.6801\n",
            "Epoch 42/50\n",
            "AE Train loss: 42.2590\n",
            "AE Val loss: 481.4428\n",
            "Epoch 43/50\n",
            "AE Train loss: 41.0780\n",
            "AE Val loss: 482.0669\n",
            "Epoch 44/50\n",
            "AE Train loss: 40.5497\n",
            "AE Val loss: 482.5985\n",
            "Epoch 45/50\n",
            "AE Train loss: 40.4802\n",
            "AE Val loss: 481.8332\n",
            "CLF Training Started-----------\n",
            "Epoch 1/50\n",
            "CLF Train loss: 0.6761, Train Accuracy: 0.5734\n",
            "CLF Val loss: 0.6460, Validation Accuracy: 0.5962\n",
            "Epoch 2/50\n",
            "CLF Train loss: 0.6268, Train Accuracy: 0.6469\n",
            "CLF Val loss: 0.6231, Validation Accuracy: 0.6058\n",
            "Epoch 3/50\n",
            "CLF Train loss: 0.5964, Train Accuracy: 0.6906\n",
            "CLF Val loss: 0.6055, Validation Accuracy: 0.6827\n",
            "Epoch 4/50\n",
            "CLF Train loss: 0.5691, Train Accuracy: 0.7250\n",
            "CLF Val loss: 0.5926, Validation Accuracy: 0.7115\n",
            "Epoch 5/50\n",
            "CLF Train loss: 0.5465, Train Accuracy: 0.7719\n",
            "CLF Val loss: 0.5822, Validation Accuracy: 0.7163\n",
            "Epoch 6/50\n",
            "CLF Train loss: 0.5189, Train Accuracy: 0.7719\n",
            "CLF Val loss: 0.5733, Validation Accuracy: 0.7115\n",
            "Epoch 7/50\n",
            "CLF Train loss: 0.5009, Train Accuracy: 0.7969\n",
            "CLF Val loss: 0.5651, Validation Accuracy: 0.7163\n",
            "Epoch 8/50\n",
            "CLF Train loss: 0.4774, Train Accuracy: 0.8234\n",
            "CLF Val loss: 0.5577, Validation Accuracy: 0.7163\n",
            "Epoch 9/50\n",
            "CLF Train loss: 0.4579, Train Accuracy: 0.8234\n",
            "CLF Val loss: 0.5501, Validation Accuracy: 0.7163\n",
            "Epoch 10/50\n",
            "CLF Train loss: 0.4359, Train Accuracy: 0.8578\n",
            "CLF Val loss: 0.5436, Validation Accuracy: 0.7115\n",
            "Epoch 11/50\n",
            "CLF Train loss: 0.4186, Train Accuracy: 0.8625\n",
            "CLF Val loss: 0.5379, Validation Accuracy: 0.7163\n",
            "Epoch 12/50\n",
            "CLF Train loss: 0.3958, Train Accuracy: 0.8797\n",
            "CLF Val loss: 0.5347, Validation Accuracy: 0.7404\n",
            "Epoch 13/50\n",
            "CLF Train loss: 0.3836, Train Accuracy: 0.8812\n",
            "CLF Val loss: 0.5319, Validation Accuracy: 0.7260\n",
            "Epoch 14/50\n",
            "CLF Train loss: 0.3544, Train Accuracy: 0.9062\n",
            "CLF Val loss: 0.5209, Validation Accuracy: 0.7308\n",
            "Epoch 15/50\n",
            "CLF Train loss: 0.3382, Train Accuracy: 0.9047\n",
            "CLF Val loss: 0.5203, Validation Accuracy: 0.7356\n",
            "Epoch 16/50\n",
            "CLF Train loss: 0.3239, Train Accuracy: 0.9172\n",
            "CLF Val loss: 0.5186, Validation Accuracy: 0.7308\n",
            "Epoch 17/50\n",
            "CLF Train loss: 0.3040, Train Accuracy: 0.9297\n",
            "CLF Val loss: 0.5131, Validation Accuracy: 0.7404\n",
            "Epoch 18/50\n",
            "CLF Train loss: 0.2848, Train Accuracy: 0.9422\n",
            "CLF Val loss: 0.5091, Validation Accuracy: 0.7404\n",
            "Epoch 19/50\n",
            "CLF Train loss: 0.2642, Train Accuracy: 0.9422\n",
            "CLF Val loss: 0.5031, Validation Accuracy: 0.7115\n",
            "Epoch 20/50\n",
            "CLF Train loss: 0.2443, Train Accuracy: 0.9563\n",
            "CLF Val loss: 0.5046, Validation Accuracy: 0.7356\n",
            "Epoch 21/50\n",
            "CLF Train loss: 0.2314, Train Accuracy: 0.9578\n",
            "CLF Val loss: 0.5013, Validation Accuracy: 0.7163\n",
            "-----------------------------\n",
            "Fold 2/10\n",
            "{'accuracy': 0.6421, 'senstivity': 0.5714, 'specificity': 0.6981, 'loss': 0.6996}\n",
            "-----------------------------\n",
            "Fold 2 weights are saved\n",
            "Number of train samples :  640\n",
            "Number of val samples :  214\n",
            "Number of test samples :  95\n",
            "AE Training Started-----------\n",
            "Epoch 1/50\n",
            "AE Train loss: 777.7848\n",
            "AE Val loss: 709.9431\n",
            "Epoch 2/50\n",
            "AE Train loss: 635.0724\n",
            "AE Val loss: 650.1182\n",
            "Epoch 3/50\n",
            "AE Train loss: 559.3632\n",
            "AE Val loss: 620.2797\n",
            "Epoch 4/50\n",
            "AE Train loss: 501.7503\n",
            "AE Val loss: 593.4777\n",
            "Epoch 5/50\n",
            "AE Train loss: 455.7368\n",
            "AE Val loss: 578.9087\n",
            "Epoch 6/50\n",
            "AE Train loss: 419.8055\n",
            "AE Val loss: 569.2892\n",
            "Epoch 7/50\n",
            "AE Train loss: 379.9450\n",
            "AE Val loss: 556.7642\n",
            "Epoch 8/50\n",
            "AE Train loss: 343.2831\n",
            "AE Val loss: 550.1927\n",
            "Epoch 9/50\n",
            "AE Train loss: 314.1009\n",
            "AE Val loss: 541.7040\n",
            "Epoch 10/50\n",
            "AE Train loss: 286.4889\n",
            "AE Val loss: 535.6288\n",
            "Epoch 11/50\n",
            "AE Train loss: 264.0297\n",
            "AE Val loss: 528.9133\n",
            "Epoch 12/50\n",
            "AE Train loss: 244.4209\n",
            "AE Val loss: 525.6954\n",
            "Epoch 13/50\n",
            "AE Train loss: 225.7004\n",
            "AE Val loss: 528.4446\n",
            "Epoch 14/50\n",
            "AE Train loss: 209.9044\n",
            "AE Val loss: 519.8437\n",
            "Epoch 15/50\n",
            "AE Train loss: 193.4612\n",
            "AE Val loss: 514.0592\n",
            "Epoch 16/50\n",
            "AE Train loss: 179.0697\n",
            "AE Val loss: 514.7316\n",
            "Epoch 17/50\n",
            "AE Train loss: 167.5710\n",
            "AE Val loss: 508.5137\n",
            "Epoch 18/50\n",
            "AE Train loss: 155.9134\n",
            "AE Val loss: 511.7529\n",
            "Epoch 19/50\n",
            "AE Train loss: 144.9928\n",
            "AE Val loss: 502.5018\n",
            "Epoch 20/50\n",
            "AE Train loss: 136.9648\n",
            "AE Val loss: 504.0792\n",
            "Epoch 21/50\n",
            "AE Train loss: 129.4910\n",
            "AE Val loss: 506.8501\n",
            "Epoch 22/50\n",
            "AE Train loss: 120.8086\n",
            "AE Val loss: 499.5854\n",
            "Epoch 23/50\n",
            "AE Train loss: 112.2253\n",
            "AE Val loss: 499.3062\n",
            "Epoch 24/50\n",
            "AE Train loss: 106.2308\n",
            "AE Val loss: 497.1789\n",
            "Epoch 25/50\n",
            "AE Train loss: 100.3613\n",
            "AE Val loss: 496.7296\n",
            "Epoch 26/50\n",
            "AE Train loss: 93.1610\n",
            "AE Val loss: 494.2602\n",
            "Epoch 27/50\n",
            "AE Train loss: 86.8289\n",
            "AE Val loss: 494.8048\n",
            "Epoch 28/50\n",
            "AE Train loss: 82.1513\n",
            "AE Val loss: 494.7057\n",
            "Epoch 29/50\n",
            "AE Train loss: 78.7617\n",
            "AE Val loss: 490.9691\n",
            "Epoch 30/50\n",
            "AE Train loss: 74.6738\n",
            "AE Val loss: 490.3934\n",
            "Epoch 31/50\n",
            "AE Train loss: 71.1786\n",
            "AE Val loss: 490.2998\n",
            "Epoch 32/50\n",
            "AE Train loss: 68.4047\n",
            "AE Val loss: 489.7919\n",
            "Epoch 33/50\n",
            "AE Train loss: 65.3215\n",
            "AE Val loss: 489.2287\n",
            "Epoch 34/50\n",
            "AE Train loss: 62.0671\n",
            "AE Val loss: 488.4609\n",
            "Epoch 35/50\n",
            "AE Train loss: 58.6299\n",
            "AE Val loss: 486.2778\n",
            "Epoch 36/50\n",
            "AE Train loss: 54.9548\n",
            "AE Val loss: 487.2774\n",
            "Epoch 37/50\n",
            "AE Train loss: 51.8980\n",
            "AE Val loss: 486.7766\n",
            "Epoch 38/50\n",
            "AE Train loss: 49.9448\n",
            "AE Val loss: 488.2739\n",
            "Epoch 39/50\n",
            "AE Train loss: 48.5405\n",
            "AE Val loss: 484.9825\n",
            "Epoch 40/50\n",
            "AE Train loss: 46.3785\n",
            "AE Val loss: 486.2714\n",
            "Epoch 41/50\n",
            "AE Train loss: 45.2912\n",
            "AE Val loss: 484.4412\n",
            "Epoch 42/50\n",
            "AE Train loss: 44.2050\n",
            "AE Val loss: 486.2022\n",
            "Epoch 43/50\n",
            "AE Train loss: 43.3941\n",
            "AE Val loss: 487.2277\n",
            "Epoch 44/50\n",
            "AE Train loss: 42.4203\n",
            "AE Val loss: 486.0089\n",
            "Epoch 45/50\n",
            "AE Train loss: 40.6148\n",
            "AE Val loss: 486.9080\n",
            "CLF Training Started-----------\n",
            "Epoch 1/50\n",
            "CLF Train loss: 0.6905, Train Accuracy: 0.5406\n",
            "CLF Val loss: 0.6633, Validation Accuracy: 0.5913\n",
            "Epoch 2/50\n",
            "CLF Train loss: 0.6472, Train Accuracy: 0.6047\n",
            "CLF Val loss: 0.6473, Validation Accuracy: 0.6010\n",
            "Epoch 3/50\n",
            "CLF Train loss: 0.6118, Train Accuracy: 0.6531\n",
            "CLF Val loss: 0.6334, Validation Accuracy: 0.6154\n",
            "Epoch 4/50\n",
            "CLF Train loss: 0.5859, Train Accuracy: 0.7063\n",
            "CLF Val loss: 0.6222, Validation Accuracy: 0.6298\n",
            "Epoch 5/50\n",
            "CLF Train loss: 0.5646, Train Accuracy: 0.7109\n",
            "CLF Val loss: 0.6120, Validation Accuracy: 0.6490\n",
            "Epoch 6/50\n",
            "CLF Train loss: 0.5451, Train Accuracy: 0.7344\n",
            "CLF Val loss: 0.6022, Validation Accuracy: 0.6635\n",
            "Epoch 7/50\n",
            "CLF Train loss: 0.5281, Train Accuracy: 0.7641\n",
            "CLF Val loss: 0.5939, Validation Accuracy: 0.6827\n",
            "Epoch 8/50\n",
            "CLF Train loss: 0.5049, Train Accuracy: 0.7937\n",
            "CLF Val loss: 0.5861, Validation Accuracy: 0.6731\n",
            "Epoch 9/50\n",
            "CLF Train loss: 0.4864, Train Accuracy: 0.7844\n",
            "CLF Val loss: 0.5776, Validation Accuracy: 0.6875\n",
            "Epoch 10/50\n",
            "CLF Train loss: 0.4648, Train Accuracy: 0.8156\n",
            "CLF Val loss: 0.5696, Validation Accuracy: 0.6923\n",
            "Epoch 11/50\n",
            "CLF Train loss: 0.4470, Train Accuracy: 0.8516\n",
            "CLF Val loss: 0.5629, Validation Accuracy: 0.7019\n",
            "Epoch 12/50\n",
            "CLF Train loss: 0.4282, Train Accuracy: 0.8484\n",
            "CLF Val loss: 0.5562, Validation Accuracy: 0.7163\n",
            "Epoch 13/50\n",
            "CLF Train loss: 0.4023, Train Accuracy: 0.8766\n",
            "CLF Val loss: 0.5488, Validation Accuracy: 0.7019\n",
            "Epoch 14/50\n",
            "CLF Train loss: 0.3849, Train Accuracy: 0.8859\n",
            "CLF Val loss: 0.5436, Validation Accuracy: 0.6971\n",
            "Epoch 15/50\n",
            "CLF Train loss: 0.3687, Train Accuracy: 0.8969\n",
            "CLF Val loss: 0.5386, Validation Accuracy: 0.7067\n",
            "Epoch 16/50\n",
            "CLF Train loss: 0.3490, Train Accuracy: 0.9094\n",
            "CLF Val loss: 0.5334, Validation Accuracy: 0.7067\n",
            "Epoch 17/50\n",
            "CLF Train loss: 0.3290, Train Accuracy: 0.9141\n",
            "CLF Val loss: 0.5293, Validation Accuracy: 0.7019\n",
            "Epoch 18/50\n",
            "CLF Train loss: 0.3080, Train Accuracy: 0.9344\n",
            "CLF Val loss: 0.5259, Validation Accuracy: 0.7212\n",
            "Epoch 19/50\n",
            "CLF Train loss: 0.2912, Train Accuracy: 0.9422\n",
            "CLF Val loss: 0.5251, Validation Accuracy: 0.7019\n",
            "Epoch 20/50\n",
            "CLF Train loss: 0.2702, Train Accuracy: 0.9437\n",
            "CLF Val loss: 0.5214, Validation Accuracy: 0.7260\n",
            "Epoch 21/50\n",
            "CLF Train loss: 0.2561, Train Accuracy: 0.9547\n",
            "CLF Val loss: 0.5232, Validation Accuracy: 0.7067\n",
            "Epoch 22/50\n",
            "CLF Train loss: 0.2377, Train Accuracy: 0.9594\n",
            "CLF Val loss: 0.5241, Validation Accuracy: 0.7163\n",
            "Epoch 23/50\n",
            "CLF Train loss: 0.2228, Train Accuracy: 0.9625\n",
            "CLF Val loss: 0.5206, Validation Accuracy: 0.7163\n",
            "Epoch 24/50\n",
            "CLF Train loss: 0.2014, Train Accuracy: 0.9828\n",
            "CLF Val loss: 0.5239, Validation Accuracy: 0.7019\n",
            "Epoch 25/50\n",
            "CLF Train loss: 0.1871, Train Accuracy: 0.9844\n",
            "CLF Val loss: 0.5245, Validation Accuracy: 0.7067\n",
            "Epoch 26/50\n",
            "CLF Train loss: 0.1753, Train Accuracy: 0.9750\n",
            "CLF Val loss: 0.5206, Validation Accuracy: 0.7163\n",
            "Epoch 27/50\n",
            "CLF Train loss: 0.1578, Train Accuracy: 0.9922\n",
            "CLF Val loss: 0.5187, Validation Accuracy: 0.7308\n",
            "Epoch 28/50\n",
            "CLF Train loss: 0.1466, Train Accuracy: 0.9906\n",
            "CLF Val loss: 0.5232, Validation Accuracy: 0.7212\n",
            "Epoch 29/50\n",
            "CLF Train loss: 0.1348, Train Accuracy: 0.9953\n",
            "CLF Val loss: 0.5319, Validation Accuracy: 0.7212\n",
            "Epoch 30/50\n",
            "CLF Train loss: 0.1260, Train Accuracy: 0.9984\n",
            "CLF Val loss: 0.5256, Validation Accuracy: 0.7067\n",
            "Epoch 31/50\n",
            "CLF Train loss: 0.1153, Train Accuracy: 0.9969\n",
            "CLF Val loss: 0.5278, Validation Accuracy: 0.7212\n",
            "Epoch 32/50\n",
            "CLF Train loss: 0.1083, Train Accuracy: 0.9984\n",
            "CLF Val loss: 0.5300, Validation Accuracy: 0.7163\n",
            "Epoch 33/50\n",
            "CLF Train loss: 0.1030, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5335, Validation Accuracy: 0.7163\n",
            "Epoch 34/50\n",
            "CLF Train loss: 0.0929, Train Accuracy: 0.9984\n",
            "CLF Val loss: 0.5434, Validation Accuracy: 0.6923\n",
            "Epoch 35/50\n",
            "CLF Train loss: 0.0873, Train Accuracy: 0.9969\n",
            "CLF Val loss: 0.5363, Validation Accuracy: 0.7163\n",
            "Epoch 36/50\n",
            "CLF Train loss: 0.0816, Train Accuracy: 0.9984\n",
            "CLF Val loss: 0.5450, Validation Accuracy: 0.7019\n",
            "-----------------------------\n",
            "Fold 3/10\n",
            "{'accuracy': 0.7474, 'senstivity': 0.619, 'specificity': 0.8491, 'loss': 0.4847}\n",
            "-----------------------------\n",
            "Fold 3 weights are saved\n",
            "Number of train samples :  640\n",
            "Number of val samples :  214\n",
            "Number of test samples :  95\n",
            "AE Training Started-----------\n",
            "Epoch 1/50\n",
            "AE Train loss: 774.3040\n",
            "AE Val loss: 701.3746\n",
            "Epoch 2/50\n",
            "AE Train loss: 630.7465\n",
            "AE Val loss: 641.8001\n",
            "Epoch 3/50\n",
            "AE Train loss: 556.7157\n",
            "AE Val loss: 610.1835\n",
            "Epoch 4/50\n",
            "AE Train loss: 498.8431\n",
            "AE Val loss: 584.9464\n",
            "Epoch 5/50\n",
            "AE Train loss: 451.9525\n",
            "AE Val loss: 569.6483\n",
            "Epoch 6/50\n",
            "AE Train loss: 410.6418\n",
            "AE Val loss: 557.7657\n",
            "Epoch 7/50\n",
            "AE Train loss: 374.3656\n",
            "AE Val loss: 558.4262\n",
            "Epoch 8/50\n",
            "AE Train loss: 342.9641\n",
            "AE Val loss: 538.1359\n",
            "Epoch 9/50\n",
            "AE Train loss: 313.4872\n",
            "AE Val loss: 532.9086\n",
            "Epoch 10/50\n",
            "AE Train loss: 286.9172\n",
            "AE Val loss: 528.1480\n",
            "Epoch 11/50\n",
            "AE Train loss: 266.0466\n",
            "AE Val loss: 521.7129\n",
            "Epoch 12/50\n",
            "AE Train loss: 243.7334\n",
            "AE Val loss: 515.8860\n",
            "Epoch 13/50\n",
            "AE Train loss: 225.2917\n",
            "AE Val loss: 512.8519\n",
            "Epoch 14/50\n",
            "AE Train loss: 206.5541\n",
            "AE Val loss: 506.0367\n",
            "Epoch 15/50\n",
            "AE Train loss: 191.3769\n",
            "AE Val loss: 510.0866\n",
            "Epoch 16/50\n",
            "AE Train loss: 178.1290\n",
            "AE Val loss: 502.4107\n",
            "Epoch 17/50\n",
            "AE Train loss: 166.2240\n",
            "AE Val loss: 501.5749\n",
            "Epoch 18/50\n",
            "AE Train loss: 155.1661\n",
            "AE Val loss: 498.5269\n",
            "Epoch 19/50\n",
            "AE Train loss: 144.7820\n",
            "AE Val loss: 496.6087\n",
            "Epoch 20/50\n",
            "AE Train loss: 135.3513\n",
            "AE Val loss: 494.7843\n",
            "Epoch 21/50\n",
            "AE Train loss: 129.0379\n",
            "AE Val loss: 494.5667\n",
            "Epoch 22/50\n",
            "AE Train loss: 119.3116\n",
            "AE Val loss: 491.9135\n",
            "Epoch 23/50\n",
            "AE Train loss: 109.9176\n",
            "AE Val loss: 492.1576\n",
            "Epoch 24/50\n",
            "AE Train loss: 103.0217\n",
            "AE Val loss: 489.2204\n",
            "Epoch 25/50\n",
            "AE Train loss: 96.4735\n",
            "AE Val loss: 486.6883\n",
            "Epoch 26/50\n",
            "AE Train loss: 90.8902\n",
            "AE Val loss: 489.4409\n",
            "Epoch 27/50\n",
            "AE Train loss: 87.7213\n",
            "AE Val loss: 487.5212\n",
            "Epoch 28/50\n",
            "AE Train loss: 84.3576\n",
            "AE Val loss: 484.2237\n",
            "Epoch 29/50\n",
            "AE Train loss: 79.6533\n",
            "AE Val loss: 483.4702\n",
            "Epoch 30/50\n",
            "AE Train loss: 74.9648\n",
            "AE Val loss: 482.4717\n",
            "Epoch 31/50\n",
            "AE Train loss: 71.1999\n",
            "AE Val loss: 483.7248\n",
            "Epoch 32/50\n",
            "AE Train loss: 67.1793\n",
            "AE Val loss: 480.9563\n",
            "Epoch 33/50\n",
            "AE Train loss: 63.6704\n",
            "AE Val loss: 481.9926\n",
            "Epoch 34/50\n",
            "AE Train loss: 61.2589\n",
            "AE Val loss: 480.0699\n",
            "Epoch 35/50\n",
            "AE Train loss: 59.0617\n",
            "AE Val loss: 483.8243\n",
            "Epoch 36/50\n",
            "AE Train loss: 56.5612\n",
            "AE Val loss: 479.8799\n",
            "Epoch 37/50\n",
            "AE Train loss: 54.2656\n",
            "AE Val loss: 480.7144\n",
            "Epoch 38/50\n",
            "AE Train loss: 52.1828\n",
            "AE Val loss: 481.5220\n",
            "Epoch 39/50\n",
            "AE Train loss: 50.3077\n",
            "AE Val loss: 478.8683\n",
            "Epoch 40/50\n",
            "AE Train loss: 47.8467\n",
            "AE Val loss: 477.5557\n",
            "Epoch 41/50\n",
            "AE Train loss: 44.7512\n",
            "AE Val loss: 477.6084\n",
            "Epoch 42/50\n",
            "AE Train loss: 42.7978\n",
            "AE Val loss: 479.2065\n",
            "Epoch 43/50\n",
            "AE Train loss: 41.4989\n",
            "AE Val loss: 478.0260\n",
            "Epoch 44/50\n",
            "AE Train loss: 39.7699\n",
            "AE Val loss: 475.8282\n",
            "Epoch 45/50\n",
            "AE Train loss: 38.6650\n",
            "AE Val loss: 479.5615\n",
            "Epoch 46/50\n",
            "AE Train loss: 36.9093\n",
            "AE Val loss: 476.4829\n",
            "Epoch 47/50\n",
            "AE Train loss: 35.7479\n",
            "AE Val loss: 475.8734\n",
            "Epoch 48/50\n",
            "AE Train loss: 35.2160\n",
            "AE Val loss: 477.7818\n",
            "CLF Training Started-----------\n",
            "Epoch 1/50\n",
            "CLF Train loss: 0.6855, Train Accuracy: 0.5641\n",
            "CLF Val loss: 0.6591, Validation Accuracy: 0.6010\n",
            "Epoch 2/50\n",
            "CLF Train loss: 0.6393, Train Accuracy: 0.6422\n",
            "CLF Val loss: 0.6375, Validation Accuracy: 0.6346\n",
            "Epoch 3/50\n",
            "CLF Train loss: 0.6137, Train Accuracy: 0.6906\n",
            "CLF Val loss: 0.6211, Validation Accuracy: 0.6683\n",
            "Epoch 4/50\n",
            "CLF Train loss: 0.5848, Train Accuracy: 0.7016\n",
            "CLF Val loss: 0.6079, Validation Accuracy: 0.6731\n",
            "Epoch 5/50\n",
            "CLF Train loss: 0.5624, Train Accuracy: 0.7359\n",
            "CLF Val loss: 0.5983, Validation Accuracy: 0.6875\n",
            "Epoch 6/50\n",
            "CLF Train loss: 0.5401, Train Accuracy: 0.7609\n",
            "CLF Val loss: 0.5904, Validation Accuracy: 0.6971\n",
            "Epoch 7/50\n",
            "CLF Train loss: 0.5122, Train Accuracy: 0.7969\n",
            "CLF Val loss: 0.5830, Validation Accuracy: 0.6923\n",
            "Epoch 8/50\n",
            "CLF Train loss: 0.4902, Train Accuracy: 0.8047\n",
            "CLF Val loss: 0.5757, Validation Accuracy: 0.6971\n",
            "Epoch 9/50\n",
            "CLF Train loss: 0.4746, Train Accuracy: 0.8266\n",
            "CLF Val loss: 0.5694, Validation Accuracy: 0.6827\n",
            "Epoch 10/50\n",
            "CLF Train loss: 0.4547, Train Accuracy: 0.8469\n",
            "CLF Val loss: 0.5644, Validation Accuracy: 0.6923\n",
            "Epoch 11/50\n",
            "CLF Train loss: 0.4350, Train Accuracy: 0.8484\n",
            "CLF Val loss: 0.5599, Validation Accuracy: 0.6971\n",
            "Epoch 12/50\n",
            "CLF Train loss: 0.4096, Train Accuracy: 0.8672\n",
            "CLF Val loss: 0.5558, Validation Accuracy: 0.7115\n",
            "Epoch 13/50\n",
            "CLF Train loss: 0.3898, Train Accuracy: 0.8922\n",
            "CLF Val loss: 0.5518, Validation Accuracy: 0.7019\n",
            "Epoch 14/50\n",
            "CLF Train loss: 0.3671, Train Accuracy: 0.8969\n",
            "CLF Val loss: 0.5481, Validation Accuracy: 0.7115\n",
            "Epoch 15/50\n",
            "CLF Train loss: 0.3520, Train Accuracy: 0.8938\n",
            "CLF Val loss: 0.5450, Validation Accuracy: 0.7260\n",
            "Epoch 16/50\n",
            "CLF Train loss: 0.3308, Train Accuracy: 0.9078\n",
            "CLF Val loss: 0.5521, Validation Accuracy: 0.7067\n",
            "Epoch 17/50\n",
            "CLF Train loss: 0.3153, Train Accuracy: 0.9203\n",
            "CLF Val loss: 0.5521, Validation Accuracy: 0.7212\n",
            "Epoch 18/50\n",
            "CLF Train loss: 0.2952, Train Accuracy: 0.9250\n",
            "CLF Val loss: 0.5425, Validation Accuracy: 0.7212\n",
            "Epoch 19/50\n",
            "CLF Train loss: 0.2751, Train Accuracy: 0.9359\n",
            "CLF Val loss: 0.5430, Validation Accuracy: 0.7115\n",
            "Epoch 20/50\n",
            "CLF Train loss: 0.2568, Train Accuracy: 0.9563\n",
            "CLF Val loss: 0.5462, Validation Accuracy: 0.7212\n",
            "Epoch 21/50\n",
            "CLF Train loss: 0.2369, Train Accuracy: 0.9609\n",
            "CLF Val loss: 0.5479, Validation Accuracy: 0.7260\n",
            "Epoch 22/50\n",
            "CLF Train loss: 0.2177, Train Accuracy: 0.9656\n",
            "CLF Val loss: 0.5447, Validation Accuracy: 0.7163\n",
            "Epoch 23/50\n",
            "CLF Train loss: 0.2014, Train Accuracy: 0.9750\n",
            "CLF Val loss: 0.5573, Validation Accuracy: 0.7308\n",
            "Epoch 24/50\n",
            "CLF Train loss: 0.1928, Train Accuracy: 0.9750\n",
            "CLF Val loss: 0.5510, Validation Accuracy: 0.7404\n",
            "Epoch 25/50\n",
            "CLF Train loss: 0.1730, Train Accuracy: 0.9812\n",
            "CLF Val loss: 0.5526, Validation Accuracy: 0.7260\n",
            "Epoch 26/50\n",
            "CLF Train loss: 0.1596, Train Accuracy: 0.9844\n",
            "CLF Val loss: 0.5573, Validation Accuracy: 0.7356\n",
            "Epoch 27/50\n",
            "CLF Train loss: 0.1455, Train Accuracy: 0.9969\n",
            "CLF Val loss: 0.5594, Validation Accuracy: 0.7356\n",
            "Epoch 28/50\n",
            "CLF Train loss: 0.1349, Train Accuracy: 0.9969\n",
            "CLF Val loss: 0.5630, Validation Accuracy: 0.7260\n",
            "Epoch 29/50\n",
            "CLF Train loss: 0.1245, Train Accuracy: 0.9969\n",
            "CLF Val loss: 0.5760, Validation Accuracy: 0.7212\n",
            "Epoch 30/50\n",
            "CLF Train loss: 0.1176, Train Accuracy: 0.9969\n",
            "CLF Val loss: 0.5720, Validation Accuracy: 0.7308\n",
            "Epoch 31/50\n",
            "CLF Train loss: 0.1071, Train Accuracy: 0.9969\n",
            "CLF Val loss: 0.5770, Validation Accuracy: 0.7308\n",
            "Epoch 32/50\n",
            "CLF Train loss: 0.0988, Train Accuracy: 0.9984\n",
            "CLF Val loss: 0.5783, Validation Accuracy: 0.7404\n",
            "Epoch 33/50\n",
            "CLF Train loss: 0.0921, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5830, Validation Accuracy: 0.7356\n",
            "-----------------------------\n",
            "Fold 4/10\n",
            "{'accuracy': 0.6737, 'senstivity': 0.619, 'specificity': 0.717, 'loss': 0.6455}\n",
            "-----------------------------\n",
            "Fold 4 weights are saved\n",
            "Number of train samples :  640\n",
            "Number of val samples :  214\n",
            "Number of test samples :  95\n",
            "AE Training Started-----------\n",
            "Epoch 1/50\n",
            "AE Train loss: 775.2638\n",
            "AE Val loss: 712.9177\n",
            "Epoch 2/50\n",
            "AE Train loss: 631.9301\n",
            "AE Val loss: 656.1179\n",
            "Epoch 3/50\n",
            "AE Train loss: 557.9537\n",
            "AE Val loss: 618.9713\n",
            "Epoch 4/50\n",
            "AE Train loss: 498.2104\n",
            "AE Val loss: 599.1807\n",
            "Epoch 5/50\n",
            "AE Train loss: 454.0272\n",
            "AE Val loss: 584.9767\n",
            "Epoch 6/50\n",
            "AE Train loss: 412.6160\n",
            "AE Val loss: 572.8234\n",
            "Epoch 7/50\n",
            "AE Train loss: 376.1888\n",
            "AE Val loss: 569.9575\n",
            "Epoch 8/50\n",
            "AE Train loss: 344.0860\n",
            "AE Val loss: 555.8851\n",
            "Epoch 9/50\n",
            "AE Train loss: 313.1291\n",
            "AE Val loss: 542.7447\n",
            "Epoch 10/50\n",
            "AE Train loss: 287.9553\n",
            "AE Val loss: 538.2819\n",
            "Epoch 11/50\n",
            "AE Train loss: 263.8272\n",
            "AE Val loss: 532.5695\n",
            "Epoch 12/50\n",
            "AE Train loss: 243.6805\n",
            "AE Val loss: 528.4399\n",
            "Epoch 13/50\n",
            "AE Train loss: 227.9666\n",
            "AE Val loss: 524.8419\n",
            "Epoch 14/50\n",
            "AE Train loss: 210.1052\n",
            "AE Val loss: 520.1934\n",
            "Epoch 15/50\n",
            "AE Train loss: 192.9150\n",
            "AE Val loss: 525.0964\n",
            "Epoch 16/50\n",
            "AE Train loss: 180.2395\n",
            "AE Val loss: 520.8038\n",
            "Epoch 17/50\n",
            "AE Train loss: 168.5199\n",
            "AE Val loss: 516.1106\n",
            "Epoch 18/50\n",
            "AE Train loss: 156.7836\n",
            "AE Val loss: 510.1442\n",
            "Epoch 19/50\n",
            "AE Train loss: 147.0563\n",
            "AE Val loss: 507.5802\n",
            "Epoch 20/50\n",
            "AE Train loss: 138.4571\n",
            "AE Val loss: 507.2297\n",
            "Epoch 21/50\n",
            "AE Train loss: 129.1482\n",
            "AE Val loss: 508.4704\n",
            "Epoch 22/50\n",
            "AE Train loss: 119.8355\n",
            "AE Val loss: 501.9530\n",
            "Epoch 23/50\n",
            "AE Train loss: 111.8373\n",
            "AE Val loss: 501.3833\n",
            "Epoch 24/50\n",
            "AE Train loss: 105.7395\n",
            "AE Val loss: 501.8759\n",
            "Epoch 25/50\n",
            "AE Train loss: 101.1265\n",
            "AE Val loss: 503.7151\n",
            "Epoch 26/50\n",
            "AE Train loss: 95.0987\n",
            "AE Val loss: 506.9962\n",
            "Epoch 27/50\n",
            "AE Train loss: 90.0300\n",
            "AE Val loss: 496.4189\n",
            "Epoch 28/50\n",
            "AE Train loss: 84.7584\n",
            "AE Val loss: 495.8093\n",
            "Epoch 29/50\n",
            "AE Train loss: 80.8245\n",
            "AE Val loss: 495.0285\n",
            "Epoch 30/50\n",
            "AE Train loss: 76.6384\n",
            "AE Val loss: 496.7574\n",
            "Epoch 31/50\n",
            "AE Train loss: 73.1235\n",
            "AE Val loss: 497.1704\n",
            "Epoch 32/50\n",
            "AE Train loss: 69.8243\n",
            "AE Val loss: 501.7470\n",
            "Epoch 33/50\n",
            "AE Train loss: 66.2988\n",
            "AE Val loss: 494.4416\n",
            "Epoch 34/50\n",
            "AE Train loss: 62.0694\n",
            "AE Val loss: 492.0099\n",
            "Epoch 35/50\n",
            "AE Train loss: 58.8226\n",
            "AE Val loss: 491.7025\n",
            "Epoch 36/50\n",
            "AE Train loss: 55.7901\n",
            "AE Val loss: 491.2680\n",
            "Epoch 37/50\n",
            "AE Train loss: 52.7706\n",
            "AE Val loss: 490.8726\n",
            "Epoch 38/50\n",
            "AE Train loss: 50.2385\n",
            "AE Val loss: 491.1206\n",
            "Epoch 39/50\n",
            "AE Train loss: 48.5011\n",
            "AE Val loss: 494.4398\n",
            "Epoch 40/50\n",
            "AE Train loss: 46.6600\n",
            "AE Val loss: 489.3364\n",
            "Epoch 41/50\n",
            "AE Train loss: 45.3121\n",
            "AE Val loss: 490.9254\n",
            "Epoch 42/50\n",
            "AE Train loss: 45.9749\n",
            "AE Val loss: 493.5107\n",
            "Epoch 43/50\n",
            "AE Train loss: 44.0941\n",
            "AE Val loss: 490.9053\n",
            "Epoch 44/50\n",
            "AE Train loss: 42.2290\n",
            "AE Val loss: 490.9302\n",
            "CLF Training Started-----------\n",
            "Epoch 1/50\n",
            "CLF Train loss: 0.6796, Train Accuracy: 0.5625\n",
            "CLF Val loss: 0.6583, Validation Accuracy: 0.5865\n",
            "Epoch 2/50\n",
            "CLF Train loss: 0.6414, Train Accuracy: 0.6344\n",
            "CLF Val loss: 0.6437, Validation Accuracy: 0.6154\n",
            "Epoch 3/50\n",
            "CLF Train loss: 0.6082, Train Accuracy: 0.6859\n",
            "CLF Val loss: 0.6349, Validation Accuracy: 0.6250\n",
            "Epoch 4/50\n",
            "CLF Train loss: 0.5739, Train Accuracy: 0.7219\n",
            "CLF Val loss: 0.6268, Validation Accuracy: 0.6346\n",
            "Epoch 5/50\n",
            "CLF Train loss: 0.5514, Train Accuracy: 0.7297\n",
            "CLF Val loss: 0.6214, Validation Accuracy: 0.6442\n",
            "Epoch 6/50\n",
            "CLF Train loss: 0.5321, Train Accuracy: 0.7500\n",
            "CLF Val loss: 0.6152, Validation Accuracy: 0.6394\n",
            "Epoch 7/50\n",
            "CLF Train loss: 0.5129, Train Accuracy: 0.7937\n",
            "CLF Val loss: 0.6080, Validation Accuracy: 0.6442\n",
            "Epoch 8/50\n",
            "CLF Train loss: 0.4904, Train Accuracy: 0.7906\n",
            "CLF Val loss: 0.6039, Validation Accuracy: 0.6490\n",
            "Epoch 9/50\n",
            "CLF Train loss: 0.4782, Train Accuracy: 0.8187\n",
            "CLF Val loss: 0.5971, Validation Accuracy: 0.6490\n",
            "Epoch 10/50\n",
            "CLF Train loss: 0.4568, Train Accuracy: 0.8156\n",
            "CLF Val loss: 0.5905, Validation Accuracy: 0.6587\n",
            "Epoch 11/50\n",
            "CLF Train loss: 0.4365, Train Accuracy: 0.8453\n",
            "CLF Val loss: 0.5868, Validation Accuracy: 0.6731\n",
            "Epoch 12/50\n",
            "CLF Train loss: 0.4157, Train Accuracy: 0.8703\n",
            "CLF Val loss: 0.5791, Validation Accuracy: 0.6731\n",
            "Epoch 13/50\n",
            "CLF Train loss: 0.3983, Train Accuracy: 0.8594\n",
            "CLF Val loss: 0.5740, Validation Accuracy: 0.6731\n",
            "Epoch 14/50\n",
            "CLF Train loss: 0.3838, Train Accuracy: 0.8703\n",
            "CLF Val loss: 0.5692, Validation Accuracy: 0.6779\n",
            "Epoch 15/50\n",
            "CLF Train loss: 0.3617, Train Accuracy: 0.8953\n",
            "CLF Val loss: 0.5633, Validation Accuracy: 0.6875\n",
            "Epoch 16/50\n",
            "CLF Train loss: 0.3441, Train Accuracy: 0.9125\n",
            "CLF Val loss: 0.5597, Validation Accuracy: 0.6779\n",
            "Epoch 17/50\n",
            "CLF Train loss: 0.3241, Train Accuracy: 0.9234\n",
            "CLF Val loss: 0.5516, Validation Accuracy: 0.6923\n",
            "Epoch 18/50\n",
            "CLF Train loss: 0.3062, Train Accuracy: 0.9266\n",
            "CLF Val loss: 0.5475, Validation Accuracy: 0.6971\n",
            "Epoch 19/50\n",
            "CLF Train loss: 0.2865, Train Accuracy: 0.9437\n",
            "CLF Val loss: 0.5443, Validation Accuracy: 0.7163\n",
            "Epoch 20/50\n",
            "CLF Train loss: 0.2685, Train Accuracy: 0.9391\n",
            "CLF Val loss: 0.5400, Validation Accuracy: 0.7163\n",
            "Epoch 21/50\n",
            "CLF Train loss: 0.2512, Train Accuracy: 0.9609\n",
            "CLF Val loss: 0.5395, Validation Accuracy: 0.7260\n",
            "Epoch 22/50\n",
            "CLF Train loss: 0.2324, Train Accuracy: 0.9688\n",
            "CLF Val loss: 0.5385, Validation Accuracy: 0.7212\n",
            "Epoch 23/50\n",
            "CLF Train loss: 0.2196, Train Accuracy: 0.9766\n",
            "CLF Val loss: 0.5310, Validation Accuracy: 0.7308\n",
            "Epoch 24/50\n",
            "CLF Train loss: 0.2018, Train Accuracy: 0.9766\n",
            "CLF Val loss: 0.5345, Validation Accuracy: 0.7212\n",
            "Epoch 25/50\n",
            "CLF Train loss: 0.1855, Train Accuracy: 0.9797\n",
            "CLF Val loss: 0.5340, Validation Accuracy: 0.6971\n",
            "Epoch 26/50\n",
            "CLF Train loss: 0.1706, Train Accuracy: 0.9969\n",
            "CLF Val loss: 0.5303, Validation Accuracy: 0.7500\n",
            "Epoch 27/50\n",
            "CLF Train loss: 0.1588, Train Accuracy: 0.9922\n",
            "CLF Val loss: 0.5334, Validation Accuracy: 0.7308\n",
            "Epoch 28/50\n",
            "CLF Train loss: 0.1450, Train Accuracy: 0.9969\n",
            "CLF Val loss: 0.5243, Validation Accuracy: 0.7260\n",
            "Epoch 29/50\n",
            "CLF Train loss: 0.1335, Train Accuracy: 0.9969\n",
            "CLF Val loss: 0.5257, Validation Accuracy: 0.7452\n",
            "Epoch 30/50\n",
            "CLF Train loss: 0.1240, Train Accuracy: 0.9984\n",
            "CLF Val loss: 0.5324, Validation Accuracy: 0.7404\n",
            "Epoch 31/50\n",
            "CLF Train loss: 0.1170, Train Accuracy: 0.9984\n",
            "CLF Val loss: 0.5279, Validation Accuracy: 0.7404\n",
            "Epoch 32/50\n",
            "CLF Train loss: 0.1062, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5321, Validation Accuracy: 0.7115\n",
            "Epoch 33/50\n",
            "CLF Train loss: 0.0997, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5371, Validation Accuracy: 0.7356\n",
            "Epoch 34/50\n",
            "CLF Train loss: 0.0904, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5353, Validation Accuracy: 0.7308\n",
            "Epoch 35/50\n",
            "CLF Train loss: 0.0856, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5314, Validation Accuracy: 0.7356\n",
            "-----------------------------\n",
            "Fold 5/10\n",
            "{'accuracy': 0.7895, 'senstivity': 0.7381, 'specificity': 0.8302, 'loss': 0.5081}\n",
            "-----------------------------\n",
            "Fold 5 weights are saved\n",
            "Number of train samples :  640\n",
            "Number of val samples :  214\n",
            "Number of test samples :  95\n",
            "AE Training Started-----------\n",
            "Epoch 1/50\n",
            "AE Train loss: 771.3712\n",
            "AE Val loss: 717.2542\n",
            "Epoch 2/50\n",
            "AE Train loss: 630.2662\n",
            "AE Val loss: 659.0128\n",
            "Epoch 3/50\n",
            "AE Train loss: 558.2859\n",
            "AE Val loss: 619.2807\n",
            "Epoch 4/50\n",
            "AE Train loss: 500.2790\n",
            "AE Val loss: 595.7087\n",
            "Epoch 5/50\n",
            "AE Train loss: 453.4714\n",
            "AE Val loss: 578.1706\n",
            "Epoch 6/50\n",
            "AE Train loss: 410.5769\n",
            "AE Val loss: 565.9015\n",
            "Epoch 7/50\n",
            "AE Train loss: 373.1704\n",
            "AE Val loss: 554.3281\n",
            "Epoch 8/50\n",
            "AE Train loss: 340.3120\n",
            "AE Val loss: 547.3098\n",
            "Epoch 9/50\n",
            "AE Train loss: 308.9606\n",
            "AE Val loss: 543.0408\n",
            "Epoch 10/50\n",
            "AE Train loss: 283.7477\n",
            "AE Val loss: 534.5332\n",
            "Epoch 11/50\n",
            "AE Train loss: 263.6554\n",
            "AE Val loss: 533.9983\n",
            "Epoch 12/50\n",
            "AE Train loss: 244.3147\n",
            "AE Val loss: 531.3430\n",
            "Epoch 13/50\n",
            "AE Train loss: 224.3427\n",
            "AE Val loss: 517.6260\n",
            "Epoch 14/50\n",
            "AE Train loss: 204.8916\n",
            "AE Val loss: 516.0706\n",
            "Epoch 15/50\n",
            "AE Train loss: 192.7192\n",
            "AE Val loss: 513.1557\n",
            "Epoch 16/50\n",
            "AE Train loss: 177.6694\n",
            "AE Val loss: 511.2414\n",
            "Epoch 17/50\n",
            "AE Train loss: 165.5219\n",
            "AE Val loss: 505.2008\n",
            "Epoch 18/50\n",
            "AE Train loss: 154.2641\n",
            "AE Val loss: 502.8894\n",
            "Epoch 19/50\n",
            "AE Train loss: 143.6478\n",
            "AE Val loss: 501.1033\n",
            "Epoch 20/50\n",
            "AE Train loss: 134.1615\n",
            "AE Val loss: 498.6795\n",
            "Epoch 21/50\n",
            "AE Train loss: 125.8666\n",
            "AE Val loss: 499.6637\n",
            "Epoch 22/50\n",
            "AE Train loss: 119.9498\n",
            "AE Val loss: 497.1008\n",
            "Epoch 23/50\n",
            "AE Train loss: 112.2576\n",
            "AE Val loss: 495.4803\n",
            "Epoch 24/50\n",
            "AE Train loss: 105.1784\n",
            "AE Val loss: 497.0119\n",
            "Epoch 25/50\n",
            "AE Train loss: 98.9153\n",
            "AE Val loss: 495.6501\n",
            "Epoch 26/50\n",
            "AE Train loss: 93.3855\n",
            "AE Val loss: 497.7922\n",
            "Epoch 27/50\n",
            "AE Train loss: 88.8381\n",
            "AE Val loss: 490.2377\n",
            "Epoch 28/50\n",
            "AE Train loss: 83.1876\n",
            "AE Val loss: 489.5565\n",
            "Epoch 29/50\n",
            "AE Train loss: 77.8473\n",
            "AE Val loss: 493.0915\n",
            "Epoch 30/50\n",
            "AE Train loss: 73.7409\n",
            "AE Val loss: 489.3638\n",
            "Epoch 31/50\n",
            "AE Train loss: 70.7456\n",
            "AE Val loss: 488.9620\n",
            "Epoch 32/50\n",
            "AE Train loss: 68.1053\n",
            "AE Val loss: 488.4581\n",
            "Epoch 33/50\n",
            "AE Train loss: 64.3220\n",
            "AE Val loss: 489.2430\n",
            "Epoch 34/50\n",
            "AE Train loss: 61.2172\n",
            "AE Val loss: 490.4044\n",
            "Epoch 35/50\n",
            "AE Train loss: 58.8706\n",
            "AE Val loss: 485.7661\n",
            "Epoch 36/50\n",
            "AE Train loss: 56.8702\n",
            "AE Val loss: 485.5940\n",
            "Epoch 37/50\n",
            "AE Train loss: 54.6288\n",
            "AE Val loss: 485.6166\n",
            "Epoch 38/50\n",
            "AE Train loss: 52.0059\n",
            "AE Val loss: 486.3178\n",
            "Epoch 39/50\n",
            "AE Train loss: 49.6703\n",
            "AE Val loss: 486.3324\n",
            "Epoch 40/50\n",
            "AE Train loss: 47.3627\n",
            "AE Val loss: 484.8037\n",
            "Epoch 41/50\n",
            "AE Train loss: 45.5695\n",
            "AE Val loss: 489.4965\n",
            "Epoch 42/50\n",
            "AE Train loss: 43.6121\n",
            "AE Val loss: 484.6870\n",
            "Epoch 43/50\n",
            "AE Train loss: 41.6408\n",
            "AE Val loss: 485.8015\n",
            "Epoch 44/50\n",
            "AE Train loss: 39.8610\n",
            "AE Val loss: 483.6014\n",
            "Epoch 45/50\n",
            "AE Train loss: 38.5658\n",
            "AE Val loss: 480.9828\n",
            "Epoch 46/50\n",
            "AE Train loss: 38.4714\n",
            "AE Val loss: 484.1198\n",
            "Epoch 47/50\n",
            "AE Train loss: 37.4582\n",
            "AE Val loss: 482.0945\n",
            "Epoch 48/50\n",
            "AE Train loss: 36.2909\n",
            "AE Val loss: 485.0808\n",
            "Epoch 49/50\n",
            "AE Train loss: 35.4455\n",
            "AE Val loss: 484.4710\n",
            "CLF Training Started-----------\n",
            "Epoch 1/50\n",
            "CLF Train loss: 0.6844, Train Accuracy: 0.5531\n",
            "CLF Val loss: 0.6408, Validation Accuracy: 0.6298\n",
            "Epoch 2/50\n",
            "CLF Train loss: 0.6502, Train Accuracy: 0.6266\n",
            "CLF Val loss: 0.6177, Validation Accuracy: 0.6538\n",
            "Epoch 3/50\n",
            "CLF Train loss: 0.6207, Train Accuracy: 0.6687\n",
            "CLF Val loss: 0.5987, Validation Accuracy: 0.7067\n",
            "Epoch 4/50\n",
            "CLF Train loss: 0.5979, Train Accuracy: 0.6937\n",
            "CLF Val loss: 0.5839, Validation Accuracy: 0.7019\n",
            "Epoch 5/50\n",
            "CLF Train loss: 0.5778, Train Accuracy: 0.7203\n",
            "CLF Val loss: 0.5720, Validation Accuracy: 0.7260\n",
            "Epoch 6/50\n",
            "CLF Train loss: 0.5555, Train Accuracy: 0.7531\n",
            "CLF Val loss: 0.5618, Validation Accuracy: 0.7308\n",
            "Epoch 7/50\n",
            "CLF Train loss: 0.5350, Train Accuracy: 0.7547\n",
            "CLF Val loss: 0.5524, Validation Accuracy: 0.7308\n",
            "Epoch 8/50\n",
            "CLF Train loss: 0.5172, Train Accuracy: 0.7750\n",
            "CLF Val loss: 0.5422, Validation Accuracy: 0.7548\n",
            "Epoch 9/50\n",
            "CLF Train loss: 0.5013, Train Accuracy: 0.7844\n",
            "CLF Val loss: 0.5349, Validation Accuracy: 0.7644\n",
            "Epoch 10/50\n",
            "CLF Train loss: 0.4835, Train Accuracy: 0.8063\n",
            "CLF Val loss: 0.5285, Validation Accuracy: 0.7596\n",
            "Epoch 11/50\n",
            "CLF Train loss: 0.4641, Train Accuracy: 0.8219\n",
            "CLF Val loss: 0.5193, Validation Accuracy: 0.7596\n",
            "Epoch 12/50\n",
            "CLF Train loss: 0.4469, Train Accuracy: 0.8609\n",
            "CLF Val loss: 0.5147, Validation Accuracy: 0.7596\n",
            "Epoch 13/50\n",
            "CLF Train loss: 0.4270, Train Accuracy: 0.8672\n",
            "CLF Val loss: 0.5034, Validation Accuracy: 0.7644\n",
            "Epoch 14/50\n",
            "CLF Train loss: 0.4056, Train Accuracy: 0.8875\n",
            "CLF Val loss: 0.5075, Validation Accuracy: 0.7500\n",
            "Epoch 15/50\n",
            "CLF Train loss: 0.3880, Train Accuracy: 0.8969\n",
            "CLF Val loss: 0.4911, Validation Accuracy: 0.7788\n",
            "Epoch 16/50\n",
            "CLF Train loss: 0.3691, Train Accuracy: 0.8969\n",
            "CLF Val loss: 0.4831, Validation Accuracy: 0.7933\n",
            "Epoch 17/50\n",
            "CLF Train loss: 0.3476, Train Accuracy: 0.9203\n",
            "CLF Val loss: 0.4773, Validation Accuracy: 0.7788\n",
            "Epoch 18/50\n",
            "CLF Train loss: 0.3283, Train Accuracy: 0.9313\n",
            "CLF Val loss: 0.4757, Validation Accuracy: 0.7644\n",
            "Epoch 19/50\n",
            "CLF Train loss: 0.3102, Train Accuracy: 0.9313\n",
            "CLF Val loss: 0.4748, Validation Accuracy: 0.7644\n",
            "Epoch 20/50\n",
            "CLF Train loss: 0.2927, Train Accuracy: 0.9344\n",
            "CLF Val loss: 0.4653, Validation Accuracy: 0.7788\n",
            "Epoch 21/50\n",
            "CLF Train loss: 0.2693, Train Accuracy: 0.9516\n",
            "CLF Val loss: 0.4585, Validation Accuracy: 0.7885\n",
            "Epoch 22/50\n",
            "CLF Train loss: 0.2557, Train Accuracy: 0.9563\n",
            "CLF Val loss: 0.4636, Validation Accuracy: 0.7692\n",
            "Epoch 23/50\n",
            "CLF Train loss: 0.2317, Train Accuracy: 0.9641\n",
            "CLF Val loss: 0.4645, Validation Accuracy: 0.7692\n",
            "Epoch 24/50\n",
            "CLF Train loss: 0.2198, Train Accuracy: 0.9750\n",
            "CLF Val loss: 0.4474, Validation Accuracy: 0.8221\n",
            "Epoch 25/50\n",
            "CLF Train loss: 0.2003, Train Accuracy: 0.9844\n",
            "CLF Val loss: 0.4432, Validation Accuracy: 0.8077\n",
            "Epoch 26/50\n",
            "CLF Train loss: 0.1866, Train Accuracy: 0.9875\n",
            "CLF Val loss: 0.4590, Validation Accuracy: 0.7644\n",
            "Epoch 27/50\n",
            "CLF Train loss: 0.1736, Train Accuracy: 0.9906\n",
            "CLF Val loss: 0.4404, Validation Accuracy: 0.8077\n",
            "Epoch 28/50\n",
            "CLF Train loss: 0.1581, Train Accuracy: 0.9875\n",
            "CLF Val loss: 0.4373, Validation Accuracy: 0.7981\n",
            "Epoch 29/50\n",
            "CLF Train loss: 0.1449, Train Accuracy: 0.9938\n",
            "CLF Val loss: 0.4682, Validation Accuracy: 0.7596\n",
            "Epoch 30/50\n",
            "CLF Train loss: 0.1367, Train Accuracy: 0.9922\n",
            "CLF Val loss: 0.4622, Validation Accuracy: 0.7740\n",
            "Epoch 31/50\n",
            "CLF Train loss: 0.1270, Train Accuracy: 0.9984\n",
            "CLF Val loss: 0.4558, Validation Accuracy: 0.7740\n",
            "Epoch 32/50\n",
            "CLF Train loss: 0.1142, Train Accuracy: 0.9969\n",
            "CLF Val loss: 0.4544, Validation Accuracy: 0.7692\n",
            "Epoch 33/50\n",
            "CLF Train loss: 0.1077, Train Accuracy: 0.9984\n",
            "CLF Val loss: 0.4419, Validation Accuracy: 0.7933\n",
            "-----------------------------\n",
            "Fold 6/10\n",
            "{'accuracy': 0.8421, 'senstivity': 0.7619, 'specificity': 0.9057, 'loss': 0.4285}\n",
            "-----------------------------\n",
            "Fold 6 weights are saved\n",
            "Number of train samples :  640\n",
            "Number of val samples :  214\n",
            "Number of test samples :  95\n",
            "AE Training Started-----------\n",
            "Epoch 1/50\n",
            "AE Train loss: 766.9912\n",
            "AE Val loss: 707.1860\n",
            "Epoch 2/50\n",
            "AE Train loss: 626.6616\n",
            "AE Val loss: 645.5602\n",
            "Epoch 3/50\n",
            "AE Train loss: 552.7473\n",
            "AE Val loss: 613.3217\n",
            "Epoch 4/50\n",
            "AE Train loss: 495.8390\n",
            "AE Val loss: 591.0756\n",
            "Epoch 5/50\n",
            "AE Train loss: 448.5957\n",
            "AE Val loss: 577.8171\n",
            "Epoch 6/50\n",
            "AE Train loss: 408.0130\n",
            "AE Val loss: 563.2038\n",
            "Epoch 7/50\n",
            "AE Train loss: 372.5163\n",
            "AE Val loss: 551.8688\n",
            "Epoch 8/50\n",
            "AE Train loss: 340.3474\n",
            "AE Val loss: 543.0986\n",
            "Epoch 9/50\n",
            "AE Train loss: 310.7114\n",
            "AE Val loss: 535.2073\n",
            "Epoch 10/50\n",
            "AE Train loss: 286.4004\n",
            "AE Val loss: 536.1350\n",
            "Epoch 11/50\n",
            "AE Train loss: 264.3427\n",
            "AE Val loss: 527.2754\n",
            "Epoch 12/50\n",
            "AE Train loss: 241.8097\n",
            "AE Val loss: 519.0161\n",
            "Epoch 13/50\n",
            "AE Train loss: 221.1591\n",
            "AE Val loss: 513.1301\n",
            "Epoch 14/50\n",
            "AE Train loss: 202.7431\n",
            "AE Val loss: 512.0596\n",
            "Epoch 15/50\n",
            "AE Train loss: 189.1000\n",
            "AE Val loss: 509.0986\n",
            "Epoch 16/50\n",
            "AE Train loss: 177.8979\n",
            "AE Val loss: 513.6790\n",
            "Epoch 17/50\n",
            "AE Train loss: 166.8860\n",
            "AE Val loss: 504.1248\n",
            "Epoch 18/50\n",
            "AE Train loss: 156.9598\n",
            "AE Val loss: 502.6422\n",
            "Epoch 19/50\n",
            "AE Train loss: 145.0653\n",
            "AE Val loss: 502.4512\n",
            "Epoch 20/50\n",
            "AE Train loss: 135.5542\n",
            "AE Val loss: 496.0059\n",
            "Epoch 21/50\n",
            "AE Train loss: 127.7047\n",
            "AE Val loss: 496.7692\n",
            "Epoch 22/50\n",
            "AE Train loss: 117.7936\n",
            "AE Val loss: 494.4019\n",
            "Epoch 23/50\n",
            "AE Train loss: 109.9307\n",
            "AE Val loss: 491.1046\n",
            "Epoch 24/50\n",
            "AE Train loss: 103.8880\n",
            "AE Val loss: 491.6146\n",
            "Epoch 25/50\n",
            "AE Train loss: 97.9234\n",
            "AE Val loss: 488.7591\n",
            "Epoch 26/50\n",
            "AE Train loss: 92.3406\n",
            "AE Val loss: 492.7162\n",
            "Epoch 27/50\n",
            "AE Train loss: 88.2869\n",
            "AE Val loss: 489.2241\n",
            "Epoch 28/50\n",
            "AE Train loss: 84.2141\n",
            "AE Val loss: 487.8237\n",
            "Epoch 29/50\n",
            "AE Train loss: 79.9001\n",
            "AE Val loss: 489.7871\n",
            "Epoch 30/50\n",
            "AE Train loss: 75.3027\n",
            "AE Val loss: 492.9853\n",
            "Epoch 31/50\n",
            "AE Train loss: 71.3114\n",
            "AE Val loss: 484.9912\n",
            "Epoch 32/50\n",
            "AE Train loss: 67.1731\n",
            "AE Val loss: 484.2277\n",
            "Epoch 33/50\n",
            "AE Train loss: 63.4735\n",
            "AE Val loss: 482.6460\n",
            "Epoch 34/50\n",
            "AE Train loss: 59.6819\n",
            "AE Val loss: 482.5942\n",
            "Epoch 35/50\n",
            "AE Train loss: 56.5916\n",
            "AE Val loss: 480.6260\n",
            "Epoch 36/50\n",
            "AE Train loss: 53.0016\n",
            "AE Val loss: 481.1138\n",
            "Epoch 37/50\n",
            "AE Train loss: 50.2994\n",
            "AE Val loss: 480.6199\n",
            "Epoch 38/50\n",
            "AE Train loss: 48.9338\n",
            "AE Val loss: 480.6309\n",
            "Epoch 39/50\n",
            "AE Train loss: 46.9638\n",
            "AE Val loss: 480.3290\n",
            "Epoch 40/50\n",
            "AE Train loss: 45.7064\n",
            "AE Val loss: 481.0601\n",
            "Epoch 41/50\n",
            "AE Train loss: 44.1955\n",
            "AE Val loss: 481.8163\n",
            "Epoch 42/50\n",
            "AE Train loss: 42.7996\n",
            "AE Val loss: 482.1361\n",
            "Epoch 43/50\n",
            "AE Train loss: 41.4263\n",
            "AE Val loss: 479.7816\n",
            "Epoch 44/50\n",
            "AE Train loss: 40.2477\n",
            "AE Val loss: 480.8916\n",
            "Epoch 45/50\n",
            "AE Train loss: 39.4207\n",
            "AE Val loss: 479.5290\n",
            "Epoch 46/50\n",
            "AE Train loss: 38.9196\n",
            "AE Val loss: 480.7566\n",
            "Epoch 47/50\n",
            "AE Train loss: 38.0366\n",
            "AE Val loss: 478.9001\n",
            "Epoch 48/50\n",
            "AE Train loss: 36.7757\n",
            "AE Val loss: 482.9116\n",
            "Epoch 49/50\n",
            "AE Train loss: 36.4058\n",
            "AE Val loss: 479.5894\n",
            "Epoch 50/50\n",
            "AE Train loss: 35.5876\n",
            "AE Val loss: 481.8302\n",
            "CLF Training Started-----------\n",
            "Epoch 1/50\n",
            "CLF Train loss: 0.7057, Train Accuracy: 0.5172\n",
            "CLF Val loss: 0.6733, Validation Accuracy: 0.5817\n",
            "Epoch 2/50\n",
            "CLF Train loss: 0.6614, Train Accuracy: 0.5875\n",
            "CLF Val loss: 0.6465, Validation Accuracy: 0.6394\n",
            "Epoch 3/50\n",
            "CLF Train loss: 0.6260, Train Accuracy: 0.6547\n",
            "CLF Val loss: 0.6266, Validation Accuracy: 0.6731\n",
            "Epoch 4/50\n",
            "CLF Train loss: 0.5998, Train Accuracy: 0.6844\n",
            "CLF Val loss: 0.6129, Validation Accuracy: 0.6731\n",
            "Epoch 5/50\n",
            "CLF Train loss: 0.5730, Train Accuracy: 0.7250\n",
            "CLF Val loss: 0.6002, Validation Accuracy: 0.6731\n",
            "Epoch 6/50\n",
            "CLF Train loss: 0.5550, Train Accuracy: 0.7422\n",
            "CLF Val loss: 0.5920, Validation Accuracy: 0.7019\n",
            "Epoch 7/50\n",
            "CLF Train loss: 0.5301, Train Accuracy: 0.7531\n",
            "CLF Val loss: 0.5821, Validation Accuracy: 0.6971\n",
            "Epoch 8/50\n",
            "CLF Train loss: 0.5093, Train Accuracy: 0.7828\n",
            "CLF Val loss: 0.5751, Validation Accuracy: 0.6971\n",
            "Epoch 9/50\n",
            "CLF Train loss: 0.4929, Train Accuracy: 0.8016\n",
            "CLF Val loss: 0.5676, Validation Accuracy: 0.6923\n",
            "Epoch 10/50\n",
            "CLF Train loss: 0.4709, Train Accuracy: 0.8125\n",
            "CLF Val loss: 0.5631, Validation Accuracy: 0.7067\n",
            "Epoch 11/50\n",
            "CLF Train loss: 0.4526, Train Accuracy: 0.8359\n",
            "CLF Val loss: 0.5544, Validation Accuracy: 0.6875\n",
            "Epoch 12/50\n",
            "CLF Train loss: 0.4302, Train Accuracy: 0.8641\n",
            "CLF Val loss: 0.5499, Validation Accuracy: 0.7067\n",
            "Epoch 13/50\n",
            "CLF Train loss: 0.4131, Train Accuracy: 0.8688\n",
            "CLF Val loss: 0.5444, Validation Accuracy: 0.7115\n",
            "Epoch 14/50\n",
            "CLF Train loss: 0.3950, Train Accuracy: 0.8656\n",
            "CLF Val loss: 0.5394, Validation Accuracy: 0.7212\n",
            "Epoch 15/50\n",
            "CLF Train loss: 0.3733, Train Accuracy: 0.9016\n",
            "CLF Val loss: 0.5392, Validation Accuracy: 0.7260\n",
            "Epoch 16/50\n",
            "CLF Train loss: 0.3550, Train Accuracy: 0.8984\n",
            "CLF Val loss: 0.5368, Validation Accuracy: 0.7404\n",
            "Epoch 17/50\n",
            "CLF Train loss: 0.3391, Train Accuracy: 0.9109\n",
            "CLF Val loss: 0.5273, Validation Accuracy: 0.7115\n",
            "Epoch 18/50\n",
            "CLF Train loss: 0.3193, Train Accuracy: 0.9141\n",
            "CLF Val loss: 0.5271, Validation Accuracy: 0.6971\n",
            "Epoch 19/50\n",
            "CLF Train loss: 0.2972, Train Accuracy: 0.9266\n",
            "CLF Val loss: 0.5231, Validation Accuracy: 0.7452\n",
            "Epoch 20/50\n",
            "CLF Train loss: 0.2819, Train Accuracy: 0.9406\n",
            "CLF Val loss: 0.5206, Validation Accuracy: 0.7308\n",
            "Epoch 21/50\n",
            "CLF Train loss: 0.2569, Train Accuracy: 0.9531\n",
            "CLF Val loss: 0.5199, Validation Accuracy: 0.7115\n",
            "Epoch 22/50\n",
            "CLF Train loss: 0.2469, Train Accuracy: 0.9500\n",
            "CLF Val loss: 0.5220, Validation Accuracy: 0.7019\n",
            "Epoch 23/50\n",
            "CLF Train loss: 0.2263, Train Accuracy: 0.9656\n",
            "CLF Val loss: 0.5169, Validation Accuracy: 0.7308\n",
            "Epoch 24/50\n",
            "CLF Train loss: 0.2096, Train Accuracy: 0.9734\n",
            "CLF Val loss: 0.5141, Validation Accuracy: 0.7452\n",
            "Epoch 25/50\n",
            "CLF Train loss: 0.1929, Train Accuracy: 0.9734\n",
            "CLF Val loss: 0.5245, Validation Accuracy: 0.7356\n",
            "Epoch 26/50\n",
            "CLF Train loss: 0.1778, Train Accuracy: 0.9812\n",
            "CLF Val loss: 0.5138, Validation Accuracy: 0.7404\n",
            "Epoch 27/50\n",
            "CLF Train loss: 0.1684, Train Accuracy: 0.9844\n",
            "CLF Val loss: 0.5250, Validation Accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "CLF Train loss: 0.1536, Train Accuracy: 0.9891\n",
            "CLF Val loss: 0.5213, Validation Accuracy: 0.7163\n",
            "Epoch 29/50\n",
            "CLF Train loss: 0.1408, Train Accuracy: 0.9938\n",
            "CLF Val loss: 0.5292, Validation Accuracy: 0.7596\n",
            "Epoch 30/50\n",
            "CLF Train loss: 0.1273, Train Accuracy: 0.9938\n",
            "CLF Val loss: 0.5242, Validation Accuracy: 0.7500\n",
            "Epoch 31/50\n",
            "CLF Train loss: 0.1188, Train Accuracy: 0.9984\n",
            "CLF Val loss: 0.5302, Validation Accuracy: 0.7596\n",
            "Epoch 32/50\n",
            "CLF Train loss: 0.1074, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5323, Validation Accuracy: 0.7644\n",
            "Epoch 33/50\n",
            "CLF Train loss: 0.0994, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5351, Validation Accuracy: 0.7452\n",
            "Epoch 34/50\n",
            "CLF Train loss: 0.0934, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5277, Validation Accuracy: 0.7500\n",
            "Epoch 35/50\n",
            "CLF Train loss: 0.0894, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5370, Validation Accuracy: 0.7596\n",
            "Epoch 36/50\n",
            "CLF Train loss: 0.0828, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5324, Validation Accuracy: 0.7500\n",
            "Epoch 37/50\n",
            "CLF Train loss: 0.0803, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5337, Validation Accuracy: 0.7548\n",
            "Epoch 38/50\n",
            "CLF Train loss: 0.0744, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5339, Validation Accuracy: 0.7452\n",
            "Epoch 39/50\n",
            "CLF Train loss: 0.0713, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5386, Validation Accuracy: 0.7548\n",
            "Epoch 40/50\n",
            "CLF Train loss: 0.0683, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5514, Validation Accuracy: 0.7548\n",
            "Epoch 41/50\n",
            "CLF Train loss: 0.0641, Train Accuracy: 1.0000\n",
            "CLF Val loss: 0.5378, Validation Accuracy: 0.7452\n",
            "-----------------------------\n",
            "Fold 7/10\n",
            "{'accuracy': 0.7684, 'senstivity': 0.7143, 'specificity': 0.8113, 'loss': 0.6178}\n",
            "-----------------------------\n",
            "Fold 7 weights are saved\n",
            "Number of train samples :  640\n",
            "Number of val samples :  214\n",
            "Number of test samples :  95\n",
            "AE Training Started-----------\n",
            "Epoch 1/50\n",
            "AE Train loss: 781.0495\n",
            "AE Val loss: 695.8493\n",
            "Epoch 2/50\n",
            "AE Train loss: 634.1216\n",
            "AE Val loss: 639.6161\n",
            "Epoch 3/50\n",
            "AE Train loss: 562.0585\n",
            "AE Val loss: 605.4805\n",
            "Epoch 4/50\n",
            "AE Train loss: 504.4347\n",
            "AE Val loss: 582.6022\n",
            "Epoch 5/50\n",
            "AE Train loss: 455.7642\n",
            "AE Val loss: 573.5128\n",
            "Epoch 6/50\n",
            "AE Train loss: 414.2445\n",
            "AE Val loss: 554.6810\n",
            "Epoch 7/50\n",
            "AE Train loss: 378.1509\n",
            "AE Val loss: 544.8552\n",
            "Epoch 8/50\n",
            "AE Train loss: 344.5813\n",
            "AE Val loss: 537.0720\n",
            "Epoch 9/50\n",
            "AE Train loss: 313.7924\n",
            "AE Val loss: 528.2382\n",
            "Epoch 10/50\n",
            "AE Train loss: 285.8413\n",
            "AE Val loss: 525.3720\n",
            "Epoch 11/50\n",
            "AE Train loss: 263.0133\n",
            "AE Val loss: 518.6243\n",
            "Epoch 12/50\n",
            "AE Train loss: 245.8573\n",
            "AE Val loss: 515.3586\n",
            "Epoch 13/50\n",
            "AE Train loss: 226.9143\n",
            "AE Val loss: 510.5616\n",
            "Epoch 14/50\n",
            "AE Train loss: 210.2314\n",
            "AE Val loss: 509.3675\n",
            "Epoch 15/50\n",
            "AE Train loss: 193.4061\n",
            "AE Val loss: 505.0769\n",
            "Epoch 16/50\n",
            "AE Train loss: 178.7912\n",
            "AE Val loss: 501.1312\n",
            "Epoch 17/50\n",
            "AE Train loss: 166.2221\n",
            "AE Val loss: 499.1310\n",
            "Epoch 18/50\n",
            "AE Train loss: 154.4088\n",
            "AE Val loss: 496.3776\n",
            "Epoch 19/50\n",
            "AE Train loss: 145.0178\n",
            "AE Val loss: 496.4598\n",
            "Epoch 20/50\n",
            "AE Train loss: 135.4650\n",
            "AE Val loss: 494.6342\n",
            "Epoch 21/50\n",
            "AE Train loss: 126.4462\n",
            "AE Val loss: 493.3007\n",
            "Epoch 22/50\n",
            "AE Train loss: 118.2282\n",
            "AE Val loss: 488.7271\n",
            "Epoch 23/50\n",
            "AE Train loss: 110.4920\n",
            "AE Val loss: 488.1841\n",
            "Epoch 24/50\n",
            "AE Train loss: 105.1289\n",
            "AE Val loss: 488.1261\n",
            "Epoch 25/50\n",
            "AE Train loss: 99.7323\n",
            "AE Val loss: 492.5641\n",
            "Epoch 26/50\n",
            "AE Train loss: 93.5187\n",
            "AE Val loss: 486.3128\n",
            "Epoch 27/50\n",
            "AE Train loss: 88.4115\n",
            "AE Val loss: 487.9526\n",
            "Epoch 28/50\n",
            "AE Train loss: 83.6501\n",
            "AE Val loss: 486.0204\n",
            "Epoch 29/50\n",
            "AE Train loss: 79.2925\n",
            "AE Val loss: 483.8885\n",
            "Epoch 30/50\n",
            "AE Train loss: 74.8494\n",
            "AE Val loss: 485.6828\n",
            "Epoch 31/50\n",
            "AE Train loss: 70.8498\n",
            "AE Val loss: 482.1321\n",
            "Epoch 32/50\n",
            "AE Train loss: 66.8509\n",
            "AE Val loss: 479.8476\n",
            "Epoch 33/50\n",
            "AE Train loss: 64.2635\n",
            "AE Val loss: 482.6624\n",
            "Epoch 34/50\n",
            "AE Train loss: 61.2658\n",
            "AE Val loss: 481.6032\n",
            "Epoch 35/50\n",
            "AE Train loss: 57.8500\n",
            "AE Val loss: 480.7957\n",
            "Epoch 36/50\n",
            "AE Train loss: 55.0026\n",
            "AE Val loss: 480.3117\n",
            "CLF Training Started-----------\n",
            "Epoch 1/50\n",
            "CLF Train loss: 0.6940, Train Accuracy: 0.5031\n",
            "CLF Val loss: 0.6602, Validation Accuracy: 0.5865\n",
            "Epoch 2/50\n",
            "CLF Train loss: 0.6502, Train Accuracy: 0.6203\n",
            "CLF Val loss: 0.6350, Validation Accuracy: 0.6202\n",
            "Epoch 3/50\n",
            "CLF Train loss: 0.6147, Train Accuracy: 0.6953\n",
            "CLF Val loss: 0.6165, Validation Accuracy: 0.6394\n",
            "Epoch 4/50\n",
            "CLF Train loss: 0.5911, Train Accuracy: 0.7094\n",
            "CLF Val loss: 0.6014, Validation Accuracy: 0.6394\n",
            "Epoch 5/50\n",
            "CLF Train loss: 0.5739, Train Accuracy: 0.7328\n",
            "CLF Val loss: 0.5892, Validation Accuracy: 0.6923\n",
            "Epoch 6/50\n",
            "CLF Train loss: 0.5496, Train Accuracy: 0.7562\n",
            "CLF Val loss: 0.5802, Validation Accuracy: 0.6923\n",
            "Epoch 7/50\n",
            "CLF Train loss: 0.5355, Train Accuracy: 0.7656\n",
            "CLF Val loss: 0.5702, Validation Accuracy: 0.7115\n",
            "Epoch 8/50\n",
            "CLF Train loss: 0.5116, Train Accuracy: 0.7906\n",
            "CLF Val loss: 0.5618, Validation Accuracy: 0.7260\n",
            "Epoch 9/50\n",
            "CLF Train loss: 0.4902, Train Accuracy: 0.8187\n",
            "CLF Val loss: 0.5554, Validation Accuracy: 0.7260\n",
            "Epoch 10/50\n",
            "CLF Train loss: 0.4717, Train Accuracy: 0.8141\n",
            "CLF Val loss: 0.5502, Validation Accuracy: 0.7163\n",
            "Epoch 11/50\n",
            "CLF Train loss: 0.4553, Train Accuracy: 0.8328\n",
            "CLF Val loss: 0.5456, Validation Accuracy: 0.7163\n",
            "Epoch 12/50\n",
            "CLF Train loss: 0.4350, Train Accuracy: 0.8562\n",
            "CLF Val loss: 0.5407, Validation Accuracy: 0.7163\n",
            "Epoch 13/50\n",
            "CLF Train loss: 0.4128, Train Accuracy: 0.8703\n",
            "CLF Val loss: 0.5355, Validation Accuracy: 0.7019\n",
            "Epoch 14/50\n",
            "CLF Train loss: 0.3893, Train Accuracy: 0.8906\n",
            "CLF Val loss: 0.5364, Validation Accuracy: 0.7019\n",
            "Epoch 15/50\n",
            "CLF Train loss: 0.3730, Train Accuracy: 0.8906\n",
            "CLF Val loss: 0.5327, Validation Accuracy: 0.7115\n",
            "Epoch 16/50\n",
            "CLF Train loss: 0.3514, Train Accuracy: 0.9047\n",
            "CLF Val loss: 0.5310, Validation Accuracy: 0.7067\n",
            "Epoch 17/50\n",
            "CLF Train loss: 0.3297, Train Accuracy: 0.9156\n",
            "CLF Val loss: 0.5267, Validation Accuracy: 0.7067\n",
            "-----------------------------\n",
            "Fold 8/10\n",
            "{'accuracy': 0.8211, 'senstivity': 0.7619, 'specificity': 0.8679, 'loss': 0.4249}\n",
            "-----------------------------\n",
            "Fold 8 weights are saved\n",
            "Number of train samples :  640\n",
            "Number of val samples :  214\n",
            "Number of test samples :  95\n",
            "AE Training Started-----------\n",
            "Epoch 1/50\n",
            "AE Train loss: 780.7180\n",
            "AE Val loss: 701.4971\n",
            "Epoch 2/50\n",
            "AE Train loss: 633.4848\n",
            "AE Val loss: 645.2691\n",
            "Epoch 3/50\n",
            "AE Train loss: 561.9009\n",
            "AE Val loss: 608.2097\n",
            "Epoch 4/50\n",
            "AE Train loss: 505.1781\n",
            "AE Val loss: 586.5461\n",
            "Epoch 5/50\n",
            "AE Train loss: 458.3290\n",
            "AE Val loss: 569.4001\n",
            "Epoch 6/50\n",
            "AE Train loss: 415.6635\n",
            "AE Val loss: 560.1566\n",
            "Epoch 7/50\n",
            "AE Train loss: 378.7577\n",
            "AE Val loss: 544.7220\n",
            "Epoch 8/50\n",
            "AE Train loss: 343.6374\n",
            "AE Val loss: 536.1385\n",
            "Epoch 9/50\n",
            "AE Train loss: 314.5147\n",
            "AE Val loss: 533.1347\n",
            "Epoch 10/50\n",
            "AE Train loss: 289.3857\n",
            "AE Val loss: 525.9595\n",
            "Epoch 11/50\n",
            "AE Train loss: 265.0319\n",
            "AE Val loss: 517.8454\n",
            "Epoch 12/50\n",
            "AE Train loss: 243.8007\n",
            "AE Val loss: 514.6508\n",
            "Epoch 13/50\n",
            "AE Train loss: 225.7396\n",
            "AE Val loss: 510.2222\n",
            "Epoch 14/50\n",
            "AE Train loss: 209.4877\n",
            "AE Val loss: 515.6487\n",
            "Epoch 15/50\n",
            "AE Train loss: 195.2935\n",
            "AE Val loss: 505.2013\n",
            "Epoch 16/50\n",
            "AE Train loss: 181.3952\n",
            "AE Val loss: 504.4020\n",
            "Epoch 17/50\n",
            "AE Train loss: 168.1388\n",
            "AE Val loss: 505.5484\n",
            "Epoch 18/50\n",
            "AE Train loss: 158.8807\n",
            "AE Val loss: 497.3052\n",
            "Epoch 19/50\n",
            "AE Train loss: 148.8176\n",
            "AE Val loss: 496.4025\n",
            "Epoch 20/50\n",
            "AE Train loss: 139.6238\n",
            "AE Val loss: 493.9730\n",
            "Epoch 21/50\n",
            "AE Train loss: 129.2204\n",
            "AE Val loss: 492.0561\n",
            "Epoch 22/50\n",
            "AE Train loss: 120.4979\n",
            "AE Val loss: 490.2302\n",
            "Epoch 23/50\n",
            "AE Train loss: 113.2372\n",
            "AE Val loss: 489.0134\n",
            "Epoch 24/50\n",
            "AE Train loss: 105.9643\n",
            "AE Val loss: 487.6090\n",
            "Epoch 25/50\n",
            "AE Train loss: 99.3798\n",
            "AE Val loss: 486.3077\n",
            "Epoch 26/50\n",
            "AE Train loss: 94.4315\n",
            "AE Val loss: 487.8581\n",
            "Epoch 27/50\n",
            "AE Train loss: 89.2931\n",
            "AE Val loss: 485.2246\n",
            "Epoch 28/50\n",
            "AE Train loss: 84.2843\n",
            "AE Val loss: 484.7110\n",
            "Epoch 29/50\n",
            "AE Train loss: 79.7502\n",
            "AE Val loss: 484.5033\n",
            "Epoch 30/50\n",
            "AE Train loss: 75.3934\n",
            "AE Val loss: 481.6383\n",
            "Epoch 31/50\n",
            "AE Train loss: 71.5453\n",
            "AE Val loss: 482.9990\n",
            "Epoch 32/50\n",
            "AE Train loss: 68.1098\n",
            "AE Val loss: 483.1919\n",
            "Epoch 33/50\n",
            "AE Train loss: 64.6369\n",
            "AE Val loss: 479.0196\n",
            "Epoch 34/50\n",
            "AE Train loss: 61.9885\n",
            "AE Val loss: 482.4632\n",
            "Epoch 35/50\n",
            "AE Train loss: 59.0807\n",
            "AE Val loss: 480.2820\n",
            "Epoch 36/50\n",
            "AE Train loss: 55.2996\n",
            "AE Val loss: 477.2300\n",
            "Epoch 37/50\n",
            "AE Train loss: 52.3713\n",
            "AE Val loss: 478.2801\n",
            "Epoch 38/50\n",
            "AE Train loss: 50.2146\n",
            "AE Val loss: 479.4012\n",
            "Epoch 39/50\n",
            "AE Train loss: 48.9183\n",
            "AE Val loss: 476.6446\n",
            "Epoch 40/50\n",
            "AE Train loss: 47.4180\n",
            "AE Val loss: 478.0171\n",
            "Epoch 41/50\n",
            "AE Train loss: 45.6127\n",
            "AE Val loss: 476.4345\n",
            "Epoch 42/50\n",
            "AE Train loss: 43.5338\n",
            "AE Val loss: 475.9396\n",
            "Epoch 43/50\n",
            "AE Train loss: 42.2345\n",
            "AE Val loss: 476.0484\n",
            "Epoch 44/50\n",
            "AE Train loss: 41.4562\n",
            "AE Val loss: 476.8909\n",
            "Epoch 45/50\n",
            "AE Train loss: 40.1332\n",
            "AE Val loss: 478.0344\n",
            "Epoch 46/50\n",
            "AE Train loss: 38.9434\n",
            "AE Val loss: 475.6374\n",
            "Epoch 47/50\n",
            "AE Train loss: 38.0238\n",
            "AE Val loss: 476.5315\n",
            "Epoch 48/50\n",
            "AE Train loss: 37.5619\n",
            "AE Val loss: 477.9319\n",
            "Epoch 49/50\n",
            "AE Train loss: 36.7345\n",
            "AE Val loss: 475.8004\n",
            "Epoch 50/50\n",
            "AE Train loss: 36.0849\n",
            "AE Val loss: 478.1101\n",
            "CLF Training Started-----------\n",
            "Epoch 1/50\n",
            "CLF Train loss: 0.6834, Train Accuracy: 0.5687\n",
            "CLF Val loss: 0.6409, Validation Accuracy: 0.5913\n",
            "Epoch 2/50\n",
            "CLF Train loss: 0.6424, Train Accuracy: 0.6109\n",
            "CLF Val loss: 0.6213, Validation Accuracy: 0.6587\n",
            "Epoch 3/50\n",
            "CLF Train loss: 0.6126, Train Accuracy: 0.6781\n",
            "CLF Val loss: 0.6094, Validation Accuracy: 0.6587\n",
            "Epoch 4/50\n",
            "CLF Train loss: 0.5864, Train Accuracy: 0.6969\n",
            "CLF Val loss: 0.5980, Validation Accuracy: 0.6875\n",
            "Epoch 5/50\n",
            "CLF Train loss: 0.5520, Train Accuracy: 0.7297\n",
            "CLF Val loss: 0.5884, Validation Accuracy: 0.7019\n",
            "Epoch 6/50\n",
            "CLF Train loss: 0.5344, Train Accuracy: 0.7500\n",
            "CLF Val loss: 0.5798, Validation Accuracy: 0.7019\n",
            "Epoch 7/50\n",
            "CLF Train loss: 0.5162, Train Accuracy: 0.7812\n",
            "CLF Val loss: 0.5735, Validation Accuracy: 0.7067\n",
            "Epoch 8/50\n",
            "CLF Train loss: 0.4938, Train Accuracy: 0.7859\n",
            "CLF Val loss: 0.5664, Validation Accuracy: 0.7163\n",
            "Epoch 9/50\n",
            "CLF Train loss: 0.4859, Train Accuracy: 0.8078\n",
            "CLF Val loss: 0.5600, Validation Accuracy: 0.7163\n",
            "Epoch 10/50\n",
            "CLF Train loss: 0.4591, Train Accuracy: 0.8219\n",
            "CLF Val loss: 0.5553, Validation Accuracy: 0.7115\n",
            "Epoch 11/50\n",
            "CLF Train loss: 0.4452, Train Accuracy: 0.8250\n",
            "CLF Val loss: 0.5506, Validation Accuracy: 0.7500\n",
            "Epoch 12/50\n",
            "CLF Train loss: 0.4200, Train Accuracy: 0.8609\n",
            "CLF Val loss: 0.5424, Validation Accuracy: 0.7404\n",
            "Epoch 13/50\n",
            "CLF Train loss: 0.4023, Train Accuracy: 0.8828\n",
            "CLF Val loss: 0.5376, Validation Accuracy: 0.7356\n",
            "Epoch 14/50\n",
            "CLF Train loss: 0.3803, Train Accuracy: 0.8828\n",
            "CLF Val loss: 0.5357, Validation Accuracy: 0.7596\n",
            "Epoch 15/50\n",
            "CLF Train loss: 0.3641, Train Accuracy: 0.9031\n",
            "CLF Val loss: 0.5319, Validation Accuracy: 0.7212\n",
            "Epoch 16/50\n",
            "CLF Train loss: 0.3414, Train Accuracy: 0.9047\n",
            "CLF Val loss: 0.5328, Validation Accuracy: 0.7644\n",
            "Epoch 17/50\n",
            "CLF Train loss: 0.3278, Train Accuracy: 0.9109\n",
            "CLF Val loss: 0.5233, Validation Accuracy: 0.7740\n",
            "Epoch 18/50\n",
            "CLF Train loss: 0.3058, Train Accuracy: 0.9328\n",
            "CLF Val loss: 0.5206, Validation Accuracy: 0.7692\n",
            "Epoch 19/50\n",
            "CLF Train loss: 0.2877, Train Accuracy: 0.9453\n",
            "CLF Val loss: 0.5184, Validation Accuracy: 0.7788\n",
            "Epoch 20/50\n",
            "CLF Train loss: 0.2684, Train Accuracy: 0.9516\n",
            "CLF Val loss: 0.5175, Validation Accuracy: 0.7500\n",
            "Epoch 21/50\n",
            "CLF Train loss: 0.2533, Train Accuracy: 0.9516\n",
            "CLF Val loss: 0.5161, Validation Accuracy: 0.7644\n",
            "Epoch 22/50\n",
            "CLF Train loss: 0.2339, Train Accuracy: 0.9578\n",
            "CLF Val loss: 0.5127, Validation Accuracy: 0.7692\n",
            "Epoch 23/50\n",
            "CLF Train loss: 0.2176, Train Accuracy: 0.9719\n",
            "CLF Val loss: 0.5105, Validation Accuracy: 0.7692\n",
            "Epoch 24/50\n",
            "CLF Train loss: 0.2075, Train Accuracy: 0.9703\n",
            "CLF Val loss: 0.5191, Validation Accuracy: 0.7788\n",
            "Epoch 25/50\n",
            "CLF Train loss: 0.1874, Train Accuracy: 0.9797\n",
            "CLF Val loss: 0.5142, Validation Accuracy: 0.7692\n",
            "Epoch 26/50\n",
            "CLF Train loss: 0.1727, Train Accuracy: 0.9828\n",
            "CLF Val loss: 0.5214, Validation Accuracy: 0.7596\n",
            "Epoch 27/50\n",
            "CLF Train loss: 0.1604, Train Accuracy: 0.9891\n",
            "CLF Val loss: 0.5313, Validation Accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "CLF Train loss: 0.1470, Train Accuracy: 0.9906\n",
            "CLF Val loss: 0.5175, Validation Accuracy: 0.7644\n",
            "-----------------------------\n",
            "Fold 9/10\n",
            "{'accuracy': 0.6947, 'senstivity': 0.5476, 'specificity': 0.8113, 'loss': 0.586}\n",
            "-----------------------------\n",
            "Fold 9 weights are saved\n",
            "Number of train samples :  641\n",
            "Number of val samples :  214\n",
            "Number of test samples :  94\n",
            "AE Training Started-----------\n",
            "Epoch 1/50\n",
            "AE Train loss: 775.3121\n",
            "AE Val loss: 711.5983\n",
            "Epoch 2/50\n",
            "AE Train loss: 632.3320\n",
            "AE Val loss: 649.1401\n",
            "Epoch 3/50\n",
            "AE Train loss: 560.1423\n",
            "AE Val loss: 618.1578\n",
            "Epoch 4/50\n",
            "AE Train loss: 502.1794\n",
            "AE Val loss: 591.4413\n",
            "Epoch 5/50\n",
            "AE Train loss: 453.1988\n",
            "AE Val loss: 575.6530\n",
            "Epoch 6/50\n",
            "AE Train loss: 412.7733\n",
            "AE Val loss: 562.1738\n",
            "Epoch 7/50\n",
            "AE Train loss: 374.7333\n",
            "AE Val loss: 551.5906\n",
            "Epoch 8/50\n",
            "AE Train loss: 343.0244\n",
            "AE Val loss: 542.3790\n",
            "Epoch 9/50\n",
            "AE Train loss: 313.4614\n",
            "AE Val loss: 534.4137\n",
            "Epoch 10/50\n",
            "AE Train loss: 289.7331\n",
            "AE Val loss: 529.7556\n",
            "Epoch 11/50\n",
            "AE Train loss: 265.5720\n",
            "AE Val loss: 524.2819\n",
            "Epoch 12/50\n",
            "AE Train loss: 242.8224\n",
            "AE Val loss: 517.3455\n",
            "Epoch 13/50\n",
            "AE Train loss: 223.0186\n",
            "AE Val loss: 514.4705\n",
            "Epoch 14/50\n",
            "AE Train loss: 207.8265\n",
            "AE Val loss: 509.2422\n",
            "Epoch 15/50\n",
            "AE Train loss: 196.6368\n",
            "AE Val loss: 507.5589\n",
            "Epoch 16/50\n",
            "AE Train loss: 181.5627\n",
            "AE Val loss: 506.1064\n",
            "Epoch 17/50\n",
            "AE Train loss: 170.3434\n",
            "AE Val loss: 502.4317\n",
            "Epoch 18/50\n",
            "AE Train loss: 157.1023\n",
            "AE Val loss: 499.8089\n",
            "Epoch 19/50\n",
            "AE Train loss: 144.6964\n",
            "AE Val loss: 497.2842\n",
            "Epoch 20/50\n",
            "AE Train loss: 134.7422\n",
            "AE Val loss: 495.5855\n",
            "Epoch 21/50\n",
            "AE Train loss: 126.4243\n",
            "AE Val loss: 491.7609\n",
            "Epoch 22/50\n",
            "AE Train loss: 118.6329\n",
            "AE Val loss: 492.6321\n",
            "Epoch 23/50\n",
            "AE Train loss: 112.8348\n",
            "AE Val loss: 494.6512\n",
            "Epoch 24/50\n",
            "AE Train loss: 106.1593\n",
            "AE Val loss: 488.6463\n",
            "Epoch 25/50\n",
            "AE Train loss: 99.0265\n",
            "AE Val loss: 490.8509\n",
            "Epoch 26/50\n",
            "AE Train loss: 92.3886\n",
            "AE Val loss: 486.5893\n",
            "Epoch 27/50\n",
            "AE Train loss: 87.1640\n",
            "AE Val loss: 486.5636\n",
            "Epoch 28/50\n",
            "AE Train loss: 82.8728\n",
            "AE Val loss: 484.8098\n",
            "Epoch 29/50\n",
            "AE Train loss: 78.2861\n",
            "AE Val loss: 482.8007\n",
            "Epoch 30/50\n",
            "AE Train loss: 73.5668\n",
            "AE Val loss: 484.1826\n",
            "Epoch 31/50\n",
            "AE Train loss: 70.3906\n",
            "AE Val loss: 481.0939\n",
            "Epoch 32/50\n",
            "AE Train loss: 66.8796\n",
            "AE Val loss: 481.8481\n",
            "Epoch 33/50\n",
            "AE Train loss: 63.3896\n",
            "AE Val loss: 482.0634\n",
            "Epoch 34/50\n",
            "AE Train loss: 60.4809\n",
            "AE Val loss: 480.2107\n",
            "Epoch 35/50\n",
            "AE Train loss: 57.8930\n",
            "AE Val loss: 479.7528\n",
            "Epoch 36/50\n",
            "AE Train loss: 55.2555\n",
            "AE Val loss: 478.5831\n",
            "Epoch 37/50\n",
            "AE Train loss: 52.0651\n",
            "AE Val loss: 478.3520\n",
            "Epoch 38/50\n",
            "AE Train loss: 49.3593\n",
            "AE Val loss: 476.9401\n",
            "Epoch 39/50\n",
            "AE Train loss: 47.7587\n",
            "AE Val loss: 479.1053\n",
            "Epoch 40/50\n",
            "AE Train loss: 46.6766\n",
            "AE Val loss: 480.1671\n",
            "Epoch 41/50\n",
            "AE Train loss: 45.4091\n",
            "AE Val loss: 479.0285\n",
            "Epoch 42/50\n",
            "AE Train loss: 43.7177\n",
            "AE Val loss: 477.9505\n",
            "CLF Training Started-----------\n",
            "Epoch 1/50\n",
            "CLF Train loss: 0.6911, Train Accuracy: 0.5188\n",
            "CLF Val loss: 0.6507, Validation Accuracy: 0.5962\n",
            "Epoch 2/50\n",
            "CLF Train loss: 0.6530, Train Accuracy: 0.6016\n",
            "CLF Val loss: 0.6238, Validation Accuracy: 0.6442\n",
            "Epoch 3/50\n",
            "CLF Train loss: 0.6212, Train Accuracy: 0.6500\n",
            "CLF Val loss: 0.6030, Validation Accuracy: 0.6779\n",
            "Epoch 4/50\n",
            "CLF Train loss: 0.5946, Train Accuracy: 0.7125\n",
            "CLF Val loss: 0.5883, Validation Accuracy: 0.6923\n",
            "Epoch 5/50\n",
            "CLF Train loss: 0.5780, Train Accuracy: 0.6984\n",
            "CLF Val loss: 0.5735, Validation Accuracy: 0.7212\n",
            "Epoch 6/50\n",
            "CLF Train loss: 0.5541, Train Accuracy: 0.7281\n",
            "CLF Val loss: 0.5613, Validation Accuracy: 0.7644\n",
            "Epoch 7/50\n",
            "CLF Train loss: 0.5325, Train Accuracy: 0.7859\n",
            "CLF Val loss: 0.5499, Validation Accuracy: 0.7548\n",
            "Epoch 8/50\n",
            "CLF Train loss: 0.5149, Train Accuracy: 0.7562\n",
            "CLF Val loss: 0.5398, Validation Accuracy: 0.7644\n",
            "Epoch 9/50\n",
            "CLF Train loss: 0.4955, Train Accuracy: 0.8109\n",
            "CLF Val loss: 0.5289, Validation Accuracy: 0.7692\n",
            "Epoch 10/50\n",
            "CLF Train loss: 0.4798, Train Accuracy: 0.7953\n",
            "CLF Val loss: 0.5229, Validation Accuracy: 0.7981\n",
            "Epoch 11/50\n",
            "CLF Train loss: 0.4568, Train Accuracy: 0.8375\n",
            "CLF Val loss: 0.5130, Validation Accuracy: 0.8077\n",
            "Epoch 12/50\n",
            "CLF Train loss: 0.4422, Train Accuracy: 0.8484\n",
            "CLF Val loss: 0.5055, Validation Accuracy: 0.7740\n",
            "Epoch 13/50\n",
            "CLF Train loss: 0.4187, Train Accuracy: 0.8500\n",
            "CLF Val loss: 0.4974, Validation Accuracy: 0.8077\n",
            "Epoch 14/50\n",
            "CLF Train loss: 0.3965, Train Accuracy: 0.8797\n",
            "CLF Val loss: 0.4891, Validation Accuracy: 0.8029\n",
            "Epoch 15/50\n",
            "CLF Train loss: 0.3790, Train Accuracy: 0.8828\n",
            "CLF Val loss: 0.4854, Validation Accuracy: 0.7837\n",
            "Epoch 16/50\n",
            "CLF Train loss: 0.3562, Train Accuracy: 0.9016\n",
            "CLF Val loss: 0.4805, Validation Accuracy: 0.7692\n",
            "Epoch 17/50\n",
            "CLF Train loss: 0.3402, Train Accuracy: 0.9047\n",
            "CLF Val loss: 0.4732, Validation Accuracy: 0.7933\n",
            "Epoch 18/50\n",
            "CLF Train loss: 0.3159, Train Accuracy: 0.9313\n",
            "CLF Val loss: 0.4732, Validation Accuracy: 0.7692\n",
            "Epoch 19/50\n",
            "CLF Train loss: 0.2959, Train Accuracy: 0.9281\n",
            "CLF Val loss: 0.4663, Validation Accuracy: 0.7981\n",
            "Epoch 20/50\n",
            "CLF Train loss: 0.2735, Train Accuracy: 0.9516\n",
            "CLF Val loss: 0.4667, Validation Accuracy: 0.7837\n",
            "-----------------------------\n",
            "Fold 10/10\n",
            "{'accuracy': 0.6383, 'senstivity': 0.4634, 'specificity': 0.7736, 'loss': 0.5244}\n",
            "-----------------------------\n",
            "Fold 10 weights are saved\n",
            "*********************************\n",
            "Average Value after 10 Folds and repeats one 1------->\n",
            "Accuracy: 0.7323, Senstivity: 0.644, Specificity: 0.8019, Loss: 0.5440000295639038\n",
            "*********************************\n",
            "Average Value after 1 Repeat:\n",
            "Accuracy: 0.7323, Senstivity: 0.644, Specificity: 0.8019, Loss: 0.5440000295639038\n",
            "4224.0108461380005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "laTjryBjYUVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MTAutoEncoder(nn.Module):\n",
        "    def __init__(self, num_inputs=990, \n",
        "                 num_latent=200, tied=True,\n",
        "                 num_classes=2, use_dropout=False):\n",
        "        super(MTAutoEncoder, self).__init__()\n",
        "        \n",
        "        self.num_latent = num_latent\n",
        "        self.num_inputs = num_inputs\n",
        "        \n",
        "        self.fc_encoder = nn.Sequential (\n",
        "                nn.Linear(self.num_inputs,4096),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(4096,1024),\n",
        "                nn.Tanh())\n",
        "        \n",
        "        self.fc_decoder = nn.Sequential (\n",
        "                nn.Linear(1024,4096),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(4096,self.num_inputs),\n",
        "                nn.Tanh())\n",
        "         \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        if use_dropout:\n",
        "            self.classifier = nn.Sequential (\n",
        "                nn.Dropout(p=0.25),\n",
        "                nn.Linear(1024, 1),\n",
        "#                 nn.Sigmoid(),\n",
        "#                 nn.Linear(128, 1),\n",
        "\n",
        "            )\n",
        "        else:\n",
        "            self.classifier = nn.Sequential (\n",
        "                nn.Linear(1024, 1),\n",
        "#                 nn.Sigmoid(),\n",
        "#                 nn.Linear(128, 1),\n",
        "            )\n",
        "            \n",
        "         \n",
        "    def forward(self, x, eval_classifier=True):\n",
        "\n",
        "        x = self.fc_encoder(x)\n",
        "        if eval_classifier:\n",
        "            x_logit = self.classifier(x)   #   .squeeze(1)\n",
        "            x_logit = self.sigmoid(x_logit)\n",
        "            return x_logit \n",
        "\n",
        "        x = self.fc_decoder(x)        \n",
        "        return x\n",
        "\n",
        "model = MTAutoEncoder()\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Retbt-o4YSv2",
        "outputId": "c174d2d1-0efa-47db-918f-19afc8ba93dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MTAutoEncoder(\n",
              "  (fc_encoder): Sequential(\n",
              "    (0): Linear(in_features=990, out_features=4096, bias=True)\n",
              "    (1): Tanh()\n",
              "    (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (3): Tanh()\n",
              "  )\n",
              "  (fc_decoder): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "    (1): Tanh()\n",
              "    (2): Linear(in_features=4096, out_features=990, bias=True)\n",
              "    (3): Tanh()\n",
              "  )\n",
              "  (sigmoid): Sigmoid()\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def attribute_image_features(algorithm, inputs, target = 1):\n",
        "    model.zero_grad()\n",
        "    model.eval()\n",
        "    tensor_attributions = algorithm.attribute(inputs = inputs, target = target, return_convergence_delta=True)  \n",
        "    return tensor_attributions"
      ],
      "metadata": {
        "id": "sSt5CcbIj5Tn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributions = []\n",
        "all_folds = pickle.load(open('./data/AllFoldsSamples.pkl', 'rb'))\n",
        "for fold in range(10):\n",
        "    fold_weights = torch.load(f'data/Weights/Fold_{fold+1}.pth', map_location=torch.device('cpu'))\n",
        "    best_clf_model = MTAutoEncoder(tied = False, num_inputs = 19900, num_latent = 512, use_dropout = True) \n",
        "    best_clf_model.load_state_dict(fold_weights)\n",
        "    best_clf_model = best_clf_model.to('cpu')\n",
        "\n",
        "    test_samples = all_folds[fold]['test']\n",
        "    x_asd, y_asd = [], []\n",
        "    for sample in test_samples : \n",
        "        if(all_corr[sample][1] == 1):\n",
        "          x_asd.append(all_corr[sample][0])\n",
        "          y_asd.append(all_corr[sample][1])\n",
        "    print('Number of ASD samples in test set : ', len(x_asd))\n",
        "\n",
        "    x_asd = torch.tensor(x_asd, dtype=torch.float)\n",
        "    y_asd = np.array(y_asd)  \n",
        "\n",
        "    y_asd_pred = best_clf_model(x_asd)\n",
        "    y_asd_pred = y_asd_pred.detach().cpu().numpy()\n",
        "    y_asd_pred = np.round(y_asd_pred)\n",
        "    y_asd_pred = np.squeeze(y_asd_pred, axis = 1)\n",
        "\n",
        "    right_indices = np.where(y_asd_pred == 1)\n",
        "    x_asd_ig = x_asd[right_indices]\n",
        "    print('Number of correctly predicted ASD samples : ', len(x_asd_ig))\n",
        "\n",
        "    ig_asd = IntegratedGradients(best_clf_model)        \n",
        "    grads_asd, delta_asd = attribute_image_features(ig_asd, inputs = x_asd_ig, target = 0)                     \n",
        "    # saliency_asd = Saliency(best_fold_model)\n",
        "    # grads_asd = saliency_asd.attribute(inputs = x_asd_ig, target = 0)\n",
        "    # grads_asd = grads_asd.squeeze().cpu().detach().numpy()\n",
        "    # grads_asd = attr_ig_asd + grads_asd\n",
        "    # grads_asd = attr_ig_asd\n",
        "    grads_asd = torch.mean(grads_asd, axis = 0)\n",
        "    grads_asd = np.array(grads_asd)\n",
        "    attributions.append(grads_asd)\n",
        "                            \n",
        "attributions = np.array(attributions)\n",
        "# np.save('./data/IG_Attributions.npy', attributions)\n",
        "print(\"Attributions shape : \", attributions.shape)"
      ],
      "metadata": {
        "id": "QaFQKIopR6r0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce81709d-598f-4dc3-ae45-190b142d5e61"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of ASD samples in test set :  42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of correctly predicted ASD samples :  28\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  23\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  26\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  28\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  31\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  32\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  29\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  32\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  23\n",
            "Number of ASD samples in test set :  41\n",
            "Number of correctly predicted ASD samples :  19\n",
            "Attributions shape :  (10, 19900)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rois_count = {}    # {roi : number of times it is repeated in all 10 folds}\n",
        "\n",
        "for grads_asd in attributions :\n",
        "  \n",
        "    attr_vals_asd = grads_asd.copy()\n",
        "    thresh = np.percentile(attr_vals_asd, 99)\n",
        "    attr_vals_asd = np.where(attr_vals_asd > thresh,  1 , 0) # check1\n",
        "    corr_matrix_asd = np.zeros((200,200))\n",
        "    corr_matrix_asd[np.triu_indices(200, 1)] = attr_vals_asd\n",
        "    print('Number of unique elements in corr_matrix : ', np.unique(corr_matrix_asd, return_counts = True))\n",
        "\n",
        "    max_sum_rows = np.sum(corr_matrix_asd, axis = 1)      # check 2\n",
        "    top_indices = np.argsort(max_sum_rows)            # Max value indices\n",
        "    top_values = max_sum_rows[top_indices]      # Max values\n",
        "\n",
        "    top20_indices  = top_indices[-20 : ]\n",
        "    top20_values = top_values[-20 : ]\n",
        "\n",
        "    print('Most repeated ROIS in ASD (Not index values): ', top20_indices + 1)\n",
        "    print('Number of times ROIS repeated in ASD : ', top20_values)\n",
        "    \n",
        "    for index, roi in enumerate(top_indices): \n",
        "        if(roi in rois_count):\n",
        "            rois_count[roi] += top_values[index]\n",
        "        else : \n",
        "          rois_count[roi] = top_values[index]        \n",
        "\n",
        "rois_count_sorted = dict(sorted(rois_count.items(), key = lambda x : x[1], reverse = True))\n",
        "print(rois_count_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_4RVBh0qnr3",
        "outputId": "bd09a900-de0f-4909-94e5-b972fb81cf1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [154  30 107 105 106  65  31  10  63  28  71  21  32  59 117  57  64  49\n",
            "  94  55]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 5. 5. 5. 6. 6. 6. 6. 6. 7. 8.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [107  21  33  28  90  93  45  71 154 130  49 106  59  46  32  55  30  17\n",
            "  77  64]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 5. 5. 5. 5. 6. 6. 6. 6. 7.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [128  94 130  93  55   8  66  31  16  36  32  45  49  57  63  64  42  46\n",
            "  30  59]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 6.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 42 106  73  65 117  87  35  49  55  17  15  45  71  46  53  32  94  30\n",
            "  84  59]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 5. 5.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 93  34  11  28  78  46 110  53  36  21  94  16  49  30  73  63  64  32\n",
            "  55  59]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 5. 6. 6. 6.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 28  45  35  11  77 119  42  47  63 106  94  17  64  32  87  46  49  30\n",
            "  59   4]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 5. 5. 5. 5. 5. 5. 5. 6.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 63  35  46  13  57 117  17  21  84 106  90   8  94  49  64  30  55  59\n",
            "  32  15]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 5. 6. 6. 6. 7. 7. 8.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 30 126  71  89  33  21  55  59  36  65  46  49  17  90  28  32  94  53\n",
            " 117  64]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 5. 6. 6. 6. 7. 9.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 73 107  90  93 129  28 106  32  16  33  44  47  49 117  42  21  94  53\n",
            "  59  64]\n",
            "Number of times ROIS repeated in ASD :  [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  4.  4.  4.  4.  5.  5.  5.\n",
            "  7. 10.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [129  36  71  99  63 170  33   3 117  74  46  21  47 106  59  28  30  55\n",
            "  49  64]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 6. 7.]\n",
            "{63: 61.0, 58: 56.0, 31: 49.0, 48: 48.0, 54: 46.0, 29: 44.0, 93: 40.0, 45: 37.0, 20: 37.0, 16: 35.0, 27: 35.0, 116: 34.0, 105: 33.0, 14: 29.0, 52: 28.0, 62: 28.0, 70: 26.0, 89: 25.0, 44: 25.0, 7: 24.0, 83: 24.0, 56: 24.0, 35: 23.0, 32: 22.0, 41: 22.0, 88: 22.0, 64: 22.0, 46: 21.0, 73: 21.0, 4: 21.0, 10: 21.0, 15: 20.0, 30: 20.0, 72: 19.0, 92: 19.0, 34: 19.0, 106: 19.0, 9: 19.0, 76: 18.0, 86: 17.0, 12: 17.0, 38: 17.0, 163: 17.0, 65: 17.0, 43: 17.0, 3: 16.0, 165: 16.0, 113: 16.0, 11: 16.0, 118: 16.0, 33: 16.0, 109: 16.0, 129: 16.0, 104: 16.0, 167: 15.0, 90: 15.0, 130: 15.0, 82: 15.0, 127: 15.0, 74: 15.0, 153: 15.0, 161: 14.0, 77: 13.0, 2: 13.0, 128: 12.0, 98: 11.0, 91: 11.0, 17: 11.0, 154: 11.0, 85: 10.0, 169: 10.0, 67: 10.0, 139: 10.0, 125: 10.0, 102: 10.0, 146: 10.0, 66: 9.0, 36: 9.0, 23: 9.0, 99: 9.0, 111: 8.0, 24: 8.0, 94: 8.0, 117: 7.0, 101: 7.0, 189: 7.0, 158: 7.0, 28: 7.0, 164: 7.0, 84: 7.0, 186: 6.0, 187: 6.0, 19: 6.0, 180: 6.0, 182: 6.0, 61: 6.0, 0: 5.0, 134: 5.0, 103: 5.0, 47: 5.0, 49: 5.0, 50: 5.0, 26: 5.0, 75: 5.0, 122: 5.0, 42: 5.0, 126: 4.0, 110: 4.0, 149: 4.0, 183: 4.0, 166: 4.0, 79: 4.0, 51: 4.0, 21: 4.0, 5: 4.0, 22: 4.0, 39: 4.0, 123: 3.0, 131: 3.0, 140: 3.0, 119: 3.0, 95: 3.0, 100: 3.0, 80: 3.0, 193: 3.0, 159: 3.0, 160: 3.0, 25: 3.0, 13: 3.0, 150: 3.0, 114: 3.0, 55: 3.0, 151: 3.0, 133: 2.0, 144: 2.0, 115: 2.0, 87: 2.0, 97: 2.0, 108: 2.0, 155: 2.0, 181: 2.0, 152: 2.0, 40: 2.0, 59: 2.0, 78: 2.0, 68: 2.0, 69: 2.0, 18: 2.0, 142: 2.0, 143: 2.0, 8: 2.0, 60: 2.0, 121: 2.0, 135: 1.0, 138: 1.0, 145: 1.0, 147: 1.0, 136: 1.0, 112: 1.0, 184: 1.0, 177: 1.0, 168: 1.0, 37: 1.0, 124: 0.0, 132: 0.0, 120: 0.0, 137: 0.0, 141: 0.0, 148: 0.0, 81: 0.0, 96: 0.0, 198: 0.0, 107: 0.0, 185: 0.0, 188: 0.0, 179: 0.0, 191: 0.0, 192: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 190: 0.0, 178: 0.0, 176: 0.0, 156: 0.0, 157: 0.0, 162: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 199: 0.0, 57: 0.0, 1: 0.0, 6: 0.0, 53: 0.0, 71: 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rois_count_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvBf8b7rcvli",
        "outputId": "acd14f8f-2085-4709-da01-abbb817a2a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{63: 61.0, 58: 56.0, 31: 49.0, 48: 48.0, 54: 46.0, 29: 44.0, 93: 40.0, 45: 37.0, 20: 37.0, 16: 35.0, 27: 35.0, 116: 34.0, 105: 33.0, 14: 29.0, 52: 28.0, 62: 28.0, 70: 26.0, 89: 25.0, 44: 25.0, 7: 24.0, 83: 24.0, 56: 24.0, 35: 23.0, 32: 22.0, 41: 22.0, 88: 22.0, 64: 22.0, 46: 21.0, 73: 21.0, 4: 21.0, 10: 21.0, 15: 20.0, 30: 20.0, 72: 19.0, 92: 19.0, 34: 19.0, 106: 19.0, 9: 19.0, 76: 18.0, 86: 17.0, 12: 17.0, 38: 17.0, 163: 17.0, 65: 17.0, 43: 17.0, 3: 16.0, 165: 16.0, 113: 16.0, 11: 16.0, 118: 16.0, 33: 16.0, 109: 16.0, 129: 16.0, 104: 16.0, 167: 15.0, 90: 15.0, 130: 15.0, 82: 15.0, 127: 15.0, 74: 15.0, 153: 15.0, 161: 14.0, 77: 13.0, 2: 13.0, 128: 12.0, 98: 11.0, 91: 11.0, 17: 11.0, 154: 11.0, 85: 10.0, 169: 10.0, 67: 10.0, 139: 10.0, 125: 10.0, 102: 10.0, 146: 10.0, 66: 9.0, 36: 9.0, 23: 9.0, 99: 9.0, 111: 8.0, 24: 8.0, 94: 8.0, 117: 7.0, 101: 7.0, 189: 7.0, 158: 7.0, 28: 7.0, 164: 7.0, 84: 7.0, 186: 6.0, 187: 6.0, 19: 6.0, 180: 6.0, 182: 6.0, 61: 6.0, 0: 5.0, 134: 5.0, 103: 5.0, 47: 5.0, 49: 5.0, 50: 5.0, 26: 5.0, 75: 5.0, 122: 5.0, 42: 5.0, 126: 4.0, 110: 4.0, 149: 4.0, 183: 4.0, 166: 4.0, 79: 4.0, 51: 4.0, 21: 4.0, 5: 4.0, 22: 4.0, 39: 4.0, 123: 3.0, 131: 3.0, 140: 3.0, 119: 3.0, 95: 3.0, 100: 3.0, 80: 3.0, 193: 3.0, 159: 3.0, 160: 3.0, 25: 3.0, 13: 3.0, 150: 3.0, 114: 3.0, 55: 3.0, 151: 3.0, 133: 2.0, 144: 2.0, 115: 2.0, 87: 2.0, 97: 2.0, 108: 2.0, 155: 2.0, 181: 2.0, 152: 2.0, 40: 2.0, 59: 2.0, 78: 2.0, 68: 2.0, 69: 2.0, 18: 2.0, 142: 2.0, 143: 2.0, 8: 2.0, 60: 2.0, 121: 2.0, 135: 1.0, 138: 1.0, 145: 1.0, 147: 1.0, 136: 1.0, 112: 1.0, 184: 1.0, 177: 1.0, 168: 1.0, 37: 1.0, 124: 0.0, 132: 0.0, 120: 0.0, 137: 0.0, 141: 0.0, 148: 0.0, 81: 0.0, 96: 0.0, 198: 0.0, 107: 0.0, 185: 0.0, 188: 0.0, 179: 0.0, 191: 0.0, 192: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 190: 0.0, 178: 0.0, 176: 0.0, 156: 0.0, 157: 0.0, 162: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 199: 0.0, 57: 0.0, 1: 0.0, 6: 0.0, 53: 0.0, 71: 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6rzw64tPTaU",
        "outputId": "15192e22-595a-4ad4-c8ab-92154759ade1"
      },
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkE6jziUZBE1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "outputId": "0efa5f8c-5a71-4ca9-edc4-04ec4bb681a9"
      },
      "source": [
        "cc200_labels = pd.read_csv('./data/CC200_ROI_labels.csv')\n",
        "# cc200_labels.head(5)\n",
        "print('ASD Associated Regions : ')\n",
        "rois = [64, 59, 32, 49, 55, 30, 94, 46]\n",
        "asd_rois = cc200_labels[cc200_labels['ROI number'].isin(rois)]\n",
        "display(asd_rois)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASD Associated Regions : \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-262d8b44-f999-4f7d-8eb2-0c33c17bf3ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROI number</th>\n",
              "      <th>volume</th>\n",
              "      <th>center of mass</th>\n",
              "      <th>Dosenbach</th>\n",
              "      <th>AAL</th>\n",
              "      <th>Eickhoff-Zilles</th>\n",
              "      <th>Talairach-Tournoux</th>\n",
              "      <th>Harvard-Oxford</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>194</td>\n",
              "      <td>(2.9;-28.0;-36.0)</td>\n",
              "      <td>[\"None\": 1.00]</td>\n",
              "      <td>[\"None\": 1.00]</td>\n",
              "      <td>[\"None\": 1.00]</td>\n",
              "      <td>[\"None\": 1.00]</td>\n",
              "      <td>[\"None\": 1.00]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>32</td>\n",
              "      <td>170</td>\n",
              "      <td>(43.5;9.9;-36.2)</td>\n",
              "      <td>[\"None\": 1.00]</td>\n",
              "      <td>[\"Temporal_Pole_Mid_R\": 0.59][\"Temporal_Inf_R\": 0.35]</td>\n",
              "      <td>[\"Right Medial Temporal Pole\": 0.61][\"Right Inferior Temporal Gyrus\": 0.26][\"None\": 0.12]</td>\n",
              "      <td>[\"Right Middle Temporal Gyrus\": 0.44][\"None\": 0.31][\"Right Superior Temporal Gyrus\": 0.25]</td>\n",
              "      <td>[\"Right Temporal Pole\": 0.96]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>46</td>\n",
              "      <td>227</td>\n",
              "      <td>(1.9;-38.2;32.2)</td>\n",
              "      <td>[\"None\": 0.84]</td>\n",
              "      <td>[\"Cingulum_Mid_R\": 0.33][\"Cingulum_Post_L\": 0.23][\"Cingulum_Mid_L\": 0.18][\"Cingulum_Post_R\": 0.18]</td>\n",
              "      <td>[\"Left Posterior Cingulate Cortex\": 0.26][\"Right Middle Cingulate Cortex\": 0.24][\"Right Posterior Cingulate Cortex\": 0.24][\"Left Middle Cingulate Cortex\": 0.14]</td>\n",
              "      <td>[\"Right Cingulate Gyrus\": 0.44][\"Left Cingulate Gyrus\": 0.26][\"Right Posterior Cingulate\": 0.14][\"Left Posterior Cingulate\": 0.13]</td>\n",
              "      <td>[\"Right Cingulate Gyrus; posterior division\": 0.74][\"Left Cingulate Gyrus; posterior division\": 0.25]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>49</td>\n",
              "      <td>222</td>\n",
              "      <td>(61.9;-21.1;-15.6)</td>\n",
              "      <td>[\"None\": 0.94]</td>\n",
              "      <td>[\"Temporal_Mid_R\": 0.64][\"Temporal_Inf_R\": 0.34]</td>\n",
              "      <td>[\"Right Inferior Temporal Gyrus\": 0.53][\"Right Middle Temporal Gyrus\": 0.47]</td>\n",
              "      <td>[\"Right Inferior Temporal Gyrus\": 0.41][\"Right Middle Temporal Gyrus\": 0.41][\"Right Fusiform Gyrus\": 0.14]</td>\n",
              "      <td>[\"Right Middle Temporal Gyrus; posterior division\": 0.75][\"Right Inferior Temporal Gyrus; posterior division\": 0.23]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>55</td>\n",
              "      <td>247</td>\n",
              "      <td>(0.3;16.3;32.3)</td>\n",
              "      <td>[\"None\": 0.83]</td>\n",
              "      <td>[\"Cingulum_Mid_L\": 0.32][\"Cingulum_Mid_R\": 0.22][\"Cingulum_Ant_L\": 0.21][\"Cingulum_Ant_R\": 0.20]</td>\n",
              "      <td>[\"Left Anterior Cingulate Cortex\": 0.32][\"Left Middle Cingulate Cortex\": 0.24][\"Right Middle Cingulate Cortex\": 0.22][\"Right Anterior Cingulate Cortex\": 0.20]</td>\n",
              "      <td>[\"Left Cingulate Gyrus\": 0.44][\"Right Cingulate Gyrus\": 0.29][\"Right Anterior Cingulate\": 0.13][\"Left Anterior Cingulate\": 0.13]</td>\n",
              "      <td>[\"Right Cingulate Gyrus; anterior division\": 0.52][\"Left Cingulate Gyrus; anterior division\": 0.27][\"Left Paracingulate Gyrus\": 0.13]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>59</td>\n",
              "      <td>240</td>\n",
              "      <td>(36.7;17.2;3.6)</td>\n",
              "      <td>[\"None\": 0.92]</td>\n",
              "      <td>[\"Insula_R\": 0.61][\"Putamen_R\": 0.20][\"Frontal_Inf_Tri_R\": 0.11]</td>\n",
              "      <td>[\"Right Insula Lobe\": 0.64][\"Right Putamen\": 0.15]</td>\n",
              "      <td>[\"Right Insula\": 0.46][\"Right Inferior Frontal Gyrus\": 0.40][\"Right Claustrum\": 0.14]</td>\n",
              "      <td>[\"Right Insular Cortex\": 0.46][\"Right Frontal Operculum Cortex\": 0.33]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>64</td>\n",
              "      <td>230</td>\n",
              "      <td>(28.8;-0.3;56.8)</td>\n",
              "      <td>[\"None\": 1.00]</td>\n",
              "      <td>[\"Frontal_Sup_R\": 0.46][\"Frontal_Mid_R\": 0.35][\"Precentral_R\": 0.20]</td>\n",
              "      <td>[\"Right Superior Frontal Gyrus\": 0.39][\"Right Middle Frontal Gyrus\": 0.37][\"RightPrecentral Gyrus\": 0.23]</td>\n",
              "      <td>[\"Right Middle Frontal Gyrus\": 0.80][\"Right Superior Frontal Gyrus\": 0.12]</td>\n",
              "      <td>[\"Right Superior Frontal Gyrus\": 0.38][\"Right Precentral Gyrus\": 0.30][\"Right Middle Frontal Gyrus\": 0.28]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>94</td>\n",
              "      <td>87</td>\n",
              "      <td>(14.2;-0.5;17.5)</td>\n",
              "      <td>[\"None\": 1.00]</td>\n",
              "      <td>[\"Caudate_R\": 0.84][\"Thalamus_R\": 0.14]</td>\n",
              "      <td>[\"Right Caudate Nucleus\": 0.77][\"Right Thalamus\": 0.16]</td>\n",
              "      <td>[\"Right Caudate\": 0.68][\"Right Thalamus\": 0.23]</td>\n",
              "      <td>[\"Right Caudate\": 0.71][\"Right Thalamus\": 0.26]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-262d8b44-f999-4f7d-8eb2-0c33c17bf3ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-262d8b44-f999-4f7d-8eb2-0c33c17bf3ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-262d8b44-f999-4f7d-8eb2-0c33c17bf3ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    ROI number   volume       center of mass       Dosenbach  \\\n",
              "29  30          194       (2.9;-28.0;-36.0)   [\"None\": 1.00]   \n",
              "31  32          170       (43.5;9.9;-36.2)    [\"None\": 1.00]   \n",
              "45  46          227       (1.9;-38.2;32.2)    [\"None\": 0.84]   \n",
              "48  49          222       (61.9;-21.1;-15.6)  [\"None\": 0.94]   \n",
              "54  55          247       (0.3;16.3;32.3)     [\"None\": 0.83]   \n",
              "58  59          240       (36.7;17.2;3.6)     [\"None\": 0.92]   \n",
              "63  64          230       (28.8;-0.3;56.8)    [\"None\": 1.00]   \n",
              "93  94          87        (14.2;-0.5;17.5)    [\"None\": 1.00]   \n",
              "\n",
              "                                                                                                   AAL  \\\n",
              "29  [\"None\": 1.00]                                                                                       \n",
              "31  [\"Temporal_Pole_Mid_R\": 0.59][\"Temporal_Inf_R\": 0.35]                                                \n",
              "45  [\"Cingulum_Mid_R\": 0.33][\"Cingulum_Post_L\": 0.23][\"Cingulum_Mid_L\": 0.18][\"Cingulum_Post_R\": 0.18]   \n",
              "48  [\"Temporal_Mid_R\": 0.64][\"Temporal_Inf_R\": 0.34]                                                     \n",
              "54  [\"Cingulum_Mid_L\": 0.32][\"Cingulum_Mid_R\": 0.22][\"Cingulum_Ant_L\": 0.21][\"Cingulum_Ant_R\": 0.20]     \n",
              "58  [\"Insula_R\": 0.61][\"Putamen_R\": 0.20][\"Frontal_Inf_Tri_R\": 0.11]                                     \n",
              "63  [\"Frontal_Sup_R\": 0.46][\"Frontal_Mid_R\": 0.35][\"Precentral_R\": 0.20]                                 \n",
              "93  [\"Caudate_R\": 0.84][\"Thalamus_R\": 0.14]                                                              \n",
              "\n",
              "                                                                                                                                                     Eickhoff-Zilles  \\\n",
              "29  [\"None\": 1.00]                                                                                                                                                     \n",
              "31  [\"Right Medial Temporal Pole\": 0.61][\"Right Inferior Temporal Gyrus\": 0.26][\"None\": 0.12]                                                                          \n",
              "45  [\"Left Posterior Cingulate Cortex\": 0.26][\"Right Middle Cingulate Cortex\": 0.24][\"Right Posterior Cingulate Cortex\": 0.24][\"Left Middle Cingulate Cortex\": 0.14]   \n",
              "48  [\"Right Inferior Temporal Gyrus\": 0.53][\"Right Middle Temporal Gyrus\": 0.47]                                                                                       \n",
              "54  [\"Left Anterior Cingulate Cortex\": 0.32][\"Left Middle Cingulate Cortex\": 0.24][\"Right Middle Cingulate Cortex\": 0.22][\"Right Anterior Cingulate Cortex\": 0.20]     \n",
              "58  [\"Right Insula Lobe\": 0.64][\"Right Putamen\": 0.15]                                                                                                                 \n",
              "63  [\"Right Superior Frontal Gyrus\": 0.39][\"Right Middle Frontal Gyrus\": 0.37][\"RightPrecentral Gyrus\": 0.23]                                                          \n",
              "93  [\"Right Caudate Nucleus\": 0.77][\"Right Thalamus\": 0.16]                                                                                                            \n",
              "\n",
              "                                                                                                                    Talairach-Tournoux  \\\n",
              "29  [\"None\": 1.00]                                                                                                                       \n",
              "31  [\"Right Middle Temporal Gyrus\": 0.44][\"None\": 0.31][\"Right Superior Temporal Gyrus\": 0.25]                                           \n",
              "45  [\"Right Cingulate Gyrus\": 0.44][\"Left Cingulate Gyrus\": 0.26][\"Right Posterior Cingulate\": 0.14][\"Left Posterior Cingulate\": 0.13]   \n",
              "48  [\"Right Inferior Temporal Gyrus\": 0.41][\"Right Middle Temporal Gyrus\": 0.41][\"Right Fusiform Gyrus\": 0.14]                           \n",
              "54  [\"Left Cingulate Gyrus\": 0.44][\"Right Cingulate Gyrus\": 0.29][\"Right Anterior Cingulate\": 0.13][\"Left Anterior Cingulate\": 0.13]     \n",
              "58  [\"Right Insula\": 0.46][\"Right Inferior Frontal Gyrus\": 0.40][\"Right Claustrum\": 0.14]                                                \n",
              "63  [\"Right Middle Frontal Gyrus\": 0.80][\"Right Superior Frontal Gyrus\": 0.12]                                                           \n",
              "93  [\"Right Caudate\": 0.68][\"Right Thalamus\": 0.23]                                                                                      \n",
              "\n",
              "                                                                                                                           Harvard-Oxford  \n",
              "29  [\"None\": 1.00]                                                                                                                         \n",
              "31  [\"Right Temporal Pole\": 0.96]                                                                                                          \n",
              "45  [\"Right Cingulate Gyrus; posterior division\": 0.74][\"Left Cingulate Gyrus; posterior division\": 0.25]                                  \n",
              "48  [\"Right Middle Temporal Gyrus; posterior division\": 0.75][\"Right Inferior Temporal Gyrus; posterior division\": 0.23]                   \n",
              "54  [\"Right Cingulate Gyrus; anterior division\": 0.52][\"Left Cingulate Gyrus; anterior division\": 0.27][\"Left Paracingulate Gyrus\": 0.13]  \n",
              "58  [\"Right Insular Cortex\": 0.46][\"Right Frontal Operculum Cortex\": 0.33]                                                                 \n",
              "63  [\"Right Superior Frontal Gyrus\": 0.38][\"Right Precentral Gyrus\": 0.30][\"Right Middle Frontal Gyrus\": 0.28]                             \n",
              "93  [\"Right Caudate\": 0.71][\"Right Thalamus\": 0.26]                                                                                        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ROIS : \n",
        "Right middle frontal gyrus(64), Right insula lobe(59), Right temporal pole(32), Right middle temporal gyrus(49), Right Caudate Nucleus(94) "
      ],
      "metadata": {
        "id": "dMmBBUqy8E8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Lift"
      ],
      "metadata": {
        "id": "Pb1l88_ih96V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK5mJmVdCV5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5009f152-d57c-45bc-fd05-fa6b878bcfcb"
      },
      "source": [
        "dl_attributions = []\n",
        "all_folds = pickle.load(open('./data/AllFoldsSamples.pkl', 'rb'))\n",
        "for fold in range(10):\n",
        "    fold_weights = torch.load(f'data/Weights/Fold_{fold+1}.pth', map_location=torch.device('cpu'))\n",
        "    best_clf_model = MTAutoEncoder(tied = False, num_inputs = 19900, num_latent = 512, use_dropout = True) \n",
        "    best_clf_model.load_state_dict(fold_weights)\n",
        "    best_clf_model = best_clf_model.to('cpu')\n",
        "\n",
        "    test_samples = all_folds[fold]['test']\n",
        "    x_asd, y_asd = [], []\n",
        "    for sample in test_samples : \n",
        "        if(all_corr[sample][1] == 1):\n",
        "          x_asd.append(all_corr[sample][0])\n",
        "          y_asd.append(all_corr[sample][1])\n",
        "    print('Number of ASD samples in test set : ', len(x_asd))\n",
        "\n",
        "    x_asd = torch.tensor(x_asd, dtype=torch.float)\n",
        "    y_asd = np.array(y_asd)  \n",
        "\n",
        "    y_asd_pred = best_clf_model(x_asd)\n",
        "    y_asd_pred = y_asd_pred.detach().cpu().numpy()\n",
        "    y_asd_pred = np.round(y_asd_pred)\n",
        "    y_asd_pred = np.squeeze(y_asd_pred, axis = 1)\n",
        "\n",
        "    right_indices = np.where(y_asd_pred == 1)\n",
        "    x_asd_dl = x_asd[right_indices]\n",
        "    print('Number of correctly predicted ASD samples : ', len(x_asd_dl))\n",
        "\n",
        "    dl_asd = DeepLift(best_clf_model)        \n",
        "    grads_asd, delta_asd = attribute_image_features(dl_asd, inputs = x_asd_dl, target = 0)                     \n",
        "    # saliency_asd = Saliency(best_fold_model)\n",
        "    # grads_asd = saliency_asd.attribute(inputs = x_asd_ig, target = 0)\n",
        "    # grads_asd = grads_asd.squeeze().cpu().detach().numpy()\n",
        "    # grads_asd = attr_ig_asd + grads_asd\n",
        "    # grads_asd = attr_ig_asd\n",
        "    grads_asd = torch.mean(grads_asd, axis = 0)\n",
        "    grads_asd = grads_asd.detach().cpu().numpy()\n",
        "    dl_attributions.append(grads_asd)\n",
        "                            \n",
        "dl_attributions = np.array(dl_attributions)\n",
        "# np.save('./data/IG_Attributions.npy', attributions)\n",
        "print(\"Attributions shape : \", dl_attributions.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/captum/_utils/gradient.py:58: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
            "  \"required_grads has been set automatically.\" % index\n",
            "/usr/local/lib/python3.7/dist-packages/captum/attr/_core/deep_lift.py:323: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
            "               activations. The hooks and attributes will be removed\n",
            "            after the attribution is finished\n",
            "  after the attribution is finished\"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  22\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  25\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  26\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  31\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  32\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  30\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  32\n",
            "Number of ASD samples in test set :  42\n",
            "Number of correctly predicted ASD samples :  23\n",
            "Number of ASD samples in test set :  41\n",
            "Number of correctly predicted ASD samples :  20\n",
            "Attributions shape :  (10, 19900)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rois_count = {}    # {roi : number of times it is repeated in all 10 folds}\n",
        "\n",
        "for grads_asd in dl_attributions :\n",
        "  \n",
        "    attr_vals_asd = grads_asd.copy()\n",
        "    thresh = np.percentile(attr_vals_asd, 99)\n",
        "    attr_vals_asd = np.where(attr_vals_asd > thresh,  1 , 0) # check1\n",
        "    corr_matrix_asd = np.zeros((200,200))\n",
        "    corr_matrix_asd[np.triu_indices(200, 1)] = attr_vals_asd\n",
        "    print('Number of unique elements in corr_matrix : ', np.unique(corr_matrix_asd, return_counts = True))\n",
        "\n",
        "    max_sum_rows = np.sum(corr_matrix_asd, axis = 1)      # check 2\n",
        "    top_indices = np.argsort(max_sum_rows)            # Max value indices\n",
        "    top_values = max_sum_rows[top_indices]      # Max values\n",
        "\n",
        "    top20_indices  = top_indices[-20 : ]\n",
        "    top20_values = top_values[-20 : ]\n",
        "\n",
        "    print('Most repeated ROIS in ASD (Not index values): ', top20_indices + 1)\n",
        "    print('Number of times ROIS repeated in ASD : ', top20_values)\n",
        "    \n",
        "    for index, roi in enumerate(top_indices): \n",
        "        if(roi in rois_count):\n",
        "            rois_count[roi] += top_values[index]\n",
        "        else : \n",
        "          rois_count[roi] = top_values[index]        \n",
        "\n",
        "rois_count_sorted = dict(sorted(rois_count.items(), key = lambda x : x[1], reverse = True))\n",
        "print(rois_count_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZKUFYkOmrEt",
        "outputId": "c5ffcd75-dc4b-45b2-e44f-32264849192c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 89 106 154 130  31  30  43  28  65  21  10  71  32  57  49  59  64 117\n",
            "  94  55]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 6. 6. 6. 6. 7. 8.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 78  93  84  33  94  28  71 130  46  49 154  77 106  32  21  59  55  17\n",
            "  30  64]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 5. 5. 5. 5. 5. 6. 6. 6. 7.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 66  28 128  15  31  93  94  39  42 105  63  36  17  57  32  49  64  30\n",
            "  46  59]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 5. 5. 6.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 64 106  21 117  35  31  28  55  45  15  17  84  49  46  59  32  71  53\n",
            "  94  30]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 6. 6. 6.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [106  93  28  31  34  36  46 110  94  53  73  21  16  49  63  30  32  59\n",
            "  55  64]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 6. 6. 6. 7.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 63 117  55  53  35  77  42  45  47  17  94 106  64  59  30  32  87  49\n",
            "   4  46]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 5. 5. 5. 5. 5. 5. 6. 6.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 87  28  63  13 117  57   8  17  21  84  90  94 106  49  30  55  64  32\n",
            "  59  15]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 5. 6. 6. 7. 7. 7. 8.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [140  30  71  55  59  65  36  33  21  17  46  89  90  28  49  32  94 117\n",
            "  53  64]\n",
            "Number of times ROIS repeated in ASD :  [3. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 5. 5. 6. 6. 7. 7. 9.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 74 119  90 129  66  77  93   5  32  47  53  13  16 117  12  21  94  49\n",
            "  59  64]\n",
            "Number of times ROIS repeated in ASD :  [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  4.  4.  4.  4.  4.  4.  5.  5.  6.\n",
            "  7. 10.]\n",
            "Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n",
            "Most repeated ROIS in ASD (Not index values):  [ 31  36 114  71  12  74   3  47  49  21 117  46  30 106  32  28  33  55\n",
            "  64  59]\n",
            "Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 6. 7. 8.]\n",
            "{63: 65.0, 58: 59.0, 31: 50.0, 48: 48.0, 29: 47.0, 54: 46.0, 93: 42.0, 20: 39.0, 45: 37.0, 16: 36.0, 27: 35.0, 116: 34.0, 105: 33.0, 52: 31.0, 14: 30.0, 70: 26.0, 89: 25.0, 62: 24.0, 56: 24.0, 35: 23.0, 88: 23.0, 32: 22.0, 15: 22.0, 92: 22.0, 7: 22.0, 44: 22.0, 83: 22.0, 30: 22.0, 64: 22.0, 46: 21.0, 73: 21.0, 4: 21.0, 76: 20.0, 9: 20.0, 41: 19.0, 10: 19.0, 86: 18.0, 113: 18.0, 65: 18.0, 163: 18.0, 106: 18.0, 34: 17.0, 12: 17.0, 38: 17.0, 11: 17.0, 72: 16.0, 3: 16.0, 165: 16.0, 130: 16.0, 43: 16.0, 104: 16.0, 129: 16.0, 118: 15.0, 74: 15.0, 33: 15.0, 109: 15.0, 153: 15.0, 167: 14.0, 2: 14.0, 90: 14.0, 127: 14.0, 82: 13.0, 128: 13.0, 161: 12.0, 77: 11.0, 139: 11.0, 98: 11.0, 67: 11.0, 146: 11.0, 91: 11.0, 154: 11.0, 85: 10.0, 99: 10.0, 17: 10.0, 24: 10.0, 169: 9.0, 66: 9.0, 84: 9.0, 125: 9.0, 102: 9.0, 111: 8.0, 23: 8.0, 36: 8.0, 164: 8.0, 94: 8.0, 101: 7.0, 189: 7.0, 158: 7.0, 42: 7.0, 186: 6.0, 187: 6.0, 28: 6.0, 19: 6.0, 182: 6.0, 180: 6.0, 117: 5.0, 183: 5.0, 50: 5.0, 47: 5.0, 21: 5.0, 75: 5.0, 122: 5.0, 0: 4.0, 131: 4.0, 140: 4.0, 119: 4.0, 87: 4.0, 103: 4.0, 110: 4.0, 61: 4.0, 26: 4.0, 5: 4.0, 39: 4.0, 123: 3.0, 126: 3.0, 134: 3.0, 95: 3.0, 97: 3.0, 108: 3.0, 100: 3.0, 193: 3.0, 159: 3.0, 160: 3.0, 166: 3.0, 79: 3.0, 49: 3.0, 51: 3.0, 13: 3.0, 142: 3.0, 150: 3.0, 114: 3.0, 55: 3.0, 151: 3.0, 143: 3.0, 133: 2.0, 144: 2.0, 115: 2.0, 149: 2.0, 152: 2.0, 181: 2.0, 80: 2.0, 22: 2.0, 25: 2.0, 59: 2.0, 40: 2.0, 78: 2.0, 18: 2.0, 69: 2.0, 8: 2.0, 37: 2.0, 60: 2.0, 132: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 145: 1.0, 147: 1.0, 96: 1.0, 112: 1.0, 155: 1.0, 184: 1.0, 177: 1.0, 68: 1.0, 6: 1.0, 138: 1.0, 121: 1.0, 124: 0.0, 141: 0.0, 120: 0.0, 81: 0.0, 148: 0.0, 198: 0.0, 107: 0.0, 185: 0.0, 188: 0.0, 179: 0.0, 191: 0.0, 192: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 190: 0.0, 178: 0.0, 176: 0.0, 156: 0.0, 157: 0.0, 162: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 168: 0.0, 199: 0.0, 57: 0.0, 53: 0.0, 71: 0.0, 1: 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delta_asd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4UCdcN0mrHn",
        "outputId": "4ec0ffb6-7985-41d6-afc3-5c2e9c030443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0448, -0.0280, -0.0142,  0.0200, -0.0104, -0.0270,  0.0045, -0.0501,\n",
              "         0.0089, -0.0137, -0.0063,  0.0045, -0.0020, -0.0252,  0.0453,  0.0029,\n",
              "        -0.0170,  0.0187,  0.0781,  0.0047])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rois = [64, 59, 49, 32, 30, 55, 94, 46]\n",
        "asd_rois = cc200_labels[cc200_labels['ROI number'].isin(rois)]\n",
        "display(asd_rois)"
      ],
      "metadata": {
        "id": "DTrhaJETh9MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l8aDLCwYmrKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KO2vGBnKmrNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(rois_count_sorted).  # Without thresholding and taking the sum. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_3TRYyBTVUK",
        "outputId": "09d135fd-5205-468a-fc96-cbff19b56d2e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{63: 0.28833801775652723, 34: 0.16755825132131255, 14: 0.15259633067985268, 70: 0.13047253297211048, 58: 0.12235610972428701, 41: 0.12204838184740958, 54: 0.11999169962167079, 29: 0.119460891259341, 48: 0.11912324991494355, 52: 0.11543538350486209, 127: 0.11251435212226324, 128: 0.10693960790720322, 88: 0.10345871149475779, 130: 0.10229100258155885, 129: 0.10204925380761753, 90: 0.09465215779146104, 20: 0.09419945080018129, 30: 0.08784245042409317, 83: 0.08576062744973681, 16: 0.08506434713670755, 72: 0.08309108378294525, 105: 0.07935774375355967, 89: 0.07755795605543256, 91: 0.07673209027984447, 82: 0.07601929354820683, 46: 0.07480984718746976, 109: 0.07152370382524624, 19: 0.06990669182987254, 45: 0.06989307003257972, 111: 0.06933357619506557, 118: 0.06875127717805271, 93: 0.06501561961407462, 65: 0.06432255460224846, 163: 0.060248144174904025, 66: 0.05892478769611261, 161: 0.05559441087351655, 110: 0.05502748499986784, 43: 0.05473448984499586, 117: 0.05314646348940971, 116: 0.05312470839891768, 125: 0.05284157795518295, 36: 0.05280198439482876, 62: 0.05253744655295338, 102: 0.05217222268775805, 108: 0.04987130275852759, 12: 0.048180330246799935, 165: 0.04734821067750166, 164: 0.04576009029960367, 56: 0.044393032996774155, 86: 0.04414353211314185, 38: 0.04393565042226278, 167: 0.043244937271131344, 57: 0.0425479574901058, 87: 0.04133974441512181, 10: 0.039711781094926756, 160: 0.036995111825119796, 47: 0.03689615936037732, 73: 0.03678561526957457, 169: 0.0358547544291699, 32: 0.03505050423381929, 24: 0.03332709884011677, 92: 0.03331232813963242, 106: 0.031193757639413143, 119: 0.030776633121194056, 126: 0.03009882553085503, 44: 0.03003014165241319, 182: 0.028435942999592075, 104: 0.028370631873877093, 84: 0.028063066113458122, 37: 0.027610485715147744, 4: 0.02746613645395753, 3: 0.026847160228006265, 153: 0.02599247364963674, 74: 0.024953806900251643, 98: 0.0248016621679322, 77: 0.023465530816658732, 50: 0.021898820555622034, 103: 0.02139667423467417, 166: 0.020258146850149324, 35: 0.01979826489681938, 76: 0.019555206204667133, 180: 0.017950420453975106, 139: 0.017497540041811657, 31: 0.01711847272572431, 85: 0.01673648875559459, 59: 0.016217787148675642, 33: 0.015977738447776675, 121: 0.014824901733032646, 131: 0.013260996897157153, 184: 0.011595208891585766, 162: 0.011336585101130038, 7: 0.0104168687123582, 154: 0.009855634280137008, 155: 0.009696737849780066, 158: 0.008678100668898814, 186: 0.008210723153331316, 170: 0.007712592427359191, 181: 0.006704557635403506, 101: 0.006207785196337427, 193: 0.005809162419216174, 183: 0.003934595468469482, 64: 0.003506429211504095, 51: 0.0034010491216618617, 192: 0.003274373618109859, 123: 0.0025657193646154105, 188: 0.0020769493429090824, 179: 0.0010216755165629145, 197: 0.0010188271099936684, 189: 0.0006010396994345813, 187: 0.00029409029313882365, 198: 0.00011403467930008336, 199: 0.0, 67: -0.0005161204381473816, 168: -0.0007164271919293302, 190: -0.0009075100557962654, 69: -0.0011473241652920087, 191: -0.0014118644331187857, 81: -0.0018185340302159332, 196: -0.002082706100564369, 185: -0.0028507422876018155, 149: -0.0035588767201282703, 9: -0.0036194223557549678, 157: -0.004488929875340442, 147: -0.004504915085442056, 134: -0.004708709841967555, 152: -0.004865027153294857, 113: -0.005265094969027212, 159: -0.0072594550881072495, 175: -0.0073440423532429655, 137: -0.007408262265374484, 114: -0.008590646307391788, 195: -0.008621245468034318, 112: -0.009502537424413312, 176: -0.0095745203846658, 27: -0.009628633378999624, 194: -0.009856572931624858, 138: -0.01035789225772693, 140: -0.010577638424533234, 151: -0.010874523902963108, 49: -0.011080862413560254, 23: -0.011983281111465679, 135: -0.012499623127393673, 95: -0.012606954399308305, 143: -0.012925881041405457, 171: -0.01305516297055968, 174: -0.013564383296299389, 122: -0.013618452887865512, 15: -0.014158575432843955, 124: -0.015971631303984834, 18: -0.016513288026496677, 68: -0.016564382491076873, 156: -0.018300347493060636, 94: -0.018601278842743266, 142: -0.019704705750509192, 146: -0.022807221722715994, 26: -0.023754320893547887, 61: -0.026189837271718627, 141: -0.02669331914206767, 133: -0.026787362209640703, 150: -0.027947915664309184, 0: -0.028255568283089408, 148: -0.029690205482707833, 120: -0.02989318181549701, 42: -0.030321729236891175, 178: -0.030658602758112455, 132: -0.030896143799309266, 177: -0.03320532477000267, 1: -0.03353668922491521, 96: -0.033643440744969375, 25: -0.03467627157431293, 80: -0.03594225509743467, 17: -0.03689347508041806, 75: -0.03706368343500563, 22: -0.03972160150037358, 97: -0.03976110669160757, 39: -0.040803977623187604, 172: -0.04146451328141268, 145: -0.04531807735509963, 60: -0.046315939670921694, 99: -0.04951986584628362, 136: -0.05095239124783012, 78: -0.05238037449772391, 100: -0.05418445561133041, 21: -0.05422739395378849, 107: -0.054563136766289856, 144: -0.06103823817392644, 115: -0.06169289756263292, 2: -0.06394825813993839, 173: -0.06586370730143272, 71: -0.0676460781827429, 40: -0.06826972638829006, 13: -0.0702247871723783, 11: -0.08075375152994747, 5: -0.08529137168418507, 53: -0.08699736148784445, 79: -0.08704765469687507, 28: -0.10789988354056877, 6: -0.11484748726741031, 8: -0.12857395497898264, 55: -0.15731916532881404}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QOFPu18_h9O_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}